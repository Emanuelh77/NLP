{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment a - Linguistics\n",
    "\n",
    "## Boise State University NLP - Dr. Kennington\n",
    "\n",
    "### Instructions and Hints:\n",
    "\n",
    "* For this assignment, we will be looking at tokenization, morphology, and syntax. \n",
    "* This will follow in a similar way as the notebook we did in class, though it will be a bit more work. \n",
    "* Answer each question (or, in some cases, follow the command)\n",
    "* Follow the instructions on the corresponding assignment Trello card for submitting your assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will be using **[Tamarian](https://www.youtube.com/watch?v=ANvlLcOTy6M)** as our example language: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'Sinda his face black his eyes red',\n",
    "    'Tamak',\n",
    "    'The river Tamak in winter',\n",
    "    'Darmok and Jalad at Tanagra',\n",
    "    'Darmok and Jalad on the ocean',\n",
    "    'Socath his eyes opened',\n",
    "#    'The beast of Tanagra Usani his army Jakka when the walls fell', # don't worry about this one\n",
    "    'Picard and Dathan at Eladrel',\n",
    "    'Marab with sails unfurled',\n",
    "    'Timba his arms open',\n",
    "    'Timba at rest'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tokenize the sentences \n",
    "\n",
    "* you will need to make sure everything is lower case\n",
    "* you will need to represent the sentences as a 2D array of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sinda', 'his', 'face', 'black', 'his', 'eyes', 'red'],\n",
       " ['tamak'],\n",
       " ['the', 'river', 'tamak', 'in', 'winter'],\n",
       " ['darmok', 'and', 'jalad', 'at', 'tanagra'],\n",
       " ['darmok', 'and', 'jalad', 'on', 'the', 'ocean'],\n",
       " ['socath', 'his', 'eyes', 'opened'],\n",
       " ['picard', 'and', 'dathan', 'at', 'eladrel'],\n",
       " ['marab', 'with', 'sails', 'unfurled'],\n",
       " ['timba', 'his', 'arms', 'open'],\n",
       " ['timba', 'at', 'rest']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = list(map(lambda x: x.lower().split(), sentences))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use a stemmer or lemmatizer \n",
    "\n",
    "- (NLTK has several) \n",
    "-  You will know your stemmer/lemmatizer did its job because plural words will no longer be plural (e.g., 'eyes' -> 'eye') and past-tense words will no longer be past-tense (e.g. 'unfurled' -> 'unfurl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sinda', 'his', 'face', 'black', 'his', 'eye', 'red'],\n",
       " ['tamak'],\n",
       " ['the', 'river', 'tamak', 'in', 'winter'],\n",
       " ['darmok', 'and', 'jalad', 'at', 'tanagra'],\n",
       " ['darmok', 'and', 'jalad', 'on', 'the', 'ocean'],\n",
       " ['socath', 'his', 'eye', 'open'],\n",
       " ['picard', 'and', 'dathan', 'at', 'eladrel'],\n",
       " ['marab', 'with', 'sail', 'unfurl'],\n",
       " ['timba', 'his', 'arm', 'open'],\n",
       " ['timba', 'at', 'rest']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import nltk.stem.snowball as stem\n",
    "\n",
    "snowball = stem.EnglishStemmer()\n",
    "lemmatized = []\n",
    "\n",
    "for elem in sentences:\n",
    "    lemmatized.append([snowball.stem(word) for word in elem])\n",
    "lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a grammar that can parse all of the sentences\n",
    "\n",
    "* Try to write as few grammar rules as possible\n",
    "* Use recursion where you can\n",
    "* Use `S` as the start symbol\n",
    "* All terminals need to be in quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "tamarian_grammar = nltk.CFG.fromstring(\"\"\"\n",
    " S -> NP\n",
    " NP -> N | N NP | N Adj | CC NP | P NP | Det NP | N Adj NP\n",
    " Det -> 'his' | 'the'\n",
    " N -> 'sinda' | 'face' | 'eye' | 'tamak' | 'river' | 'winter' | 'darmok' | 'jalad' | 'tanagra' | 'ocean' | 'socath' | 'picard' | 'eladrel' | 'dathan' | 'marab' | 'sail' | 'arm' | 'timba' | 'rest' \n",
    " P -> 'in' | 'at' | 'on' | 'with'\n",
    " Adj -> 'black' | 'red' | 'open' | 'unfurl'\n",
    " CC -> 'and' \n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Show that your grammar parses all of the sentences\n",
    "\n",
    "* Use a parser that can use a CFG (NLTK has several) \n",
    "* Make sure there is a parse tree for each of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sinda', 'his', 'face', 'black', 'his', 'eye', 'red']\n",
      "(S\n",
      "  (NP\n",
      "    (N sinda)\n",
      "    (NP\n",
      "      (Det his)\n",
      "      (NP (N face) (Adj black) (NP (Det his) (NP (N eye) (Adj red)))))))\n",
      "\n",
      "\n",
      "['tamak']\n",
      "(S (NP (N tamak)))\n",
      "\n",
      "\n",
      "['the', 'river', 'tamak', 'in', 'winter']\n",
      "(S\n",
      "  (NP\n",
      "    (Det the)\n",
      "    (NP (N river) (NP (N tamak) (NP (P in) (NP (N winter)))))))\n",
      "\n",
      "\n",
      "['darmok', 'and', 'jalad', 'at', 'tanagra']\n",
      "(S\n",
      "  (NP\n",
      "    (N darmok)\n",
      "    (NP (CC and) (NP (N jalad) (NP (P at) (NP (N tanagra)))))))\n",
      "\n",
      "\n",
      "['darmok', 'and', 'jalad', 'on', 'the', 'ocean']\n",
      "(S\n",
      "  (NP\n",
      "    (N darmok)\n",
      "    (NP\n",
      "      (CC and)\n",
      "      (NP (N jalad) (NP (P on) (NP (Det the) (NP (N ocean))))))))\n",
      "\n",
      "\n",
      "['socath', 'his', 'eye', 'open']\n",
      "(S (NP (N socath) (NP (Det his) (NP (N eye) (Adj open)))))\n",
      "\n",
      "\n",
      "['picard', 'and', 'dathan', 'at', 'eladrel']\n",
      "(S\n",
      "  (NP\n",
      "    (N picard)\n",
      "    (NP (CC and) (NP (N dathan) (NP (P at) (NP (N eladrel)))))))\n",
      "\n",
      "\n",
      "['marab', 'with', 'sail', 'unfurl']\n",
      "(S (NP (N marab) (NP (P with) (NP (N sail) (Adj unfurl)))))\n",
      "\n",
      "\n",
      "['timba', 'his', 'arm', 'open']\n",
      "(S (NP (N timba) (NP (Det his) (NP (N arm) (Adj open)))))\n",
      "\n",
      "\n",
      "['timba', 'at', 'rest']\n",
      "(S (NP (N timba) (NP (P at) (NP (N rest)))))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(tamarian_grammar)\n",
    "for sentence in lemmatized:\n",
    "    print(sentence)\n",
    "    for tree in parser.parse(sentence):\n",
    "        print(tree)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For questions 5-7, just answer in marktown/raw text. No code necessary.\n",
    "\n",
    "## 5. Does your parser have full coverage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yes, it does, it parses through all of the sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Does your parser over-generate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no, it doesn't because it only produces one parse for every sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Which sentences are ambiguous? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "none of them, there's only one parse for sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Parse this sentence:\n",
    "\n",
    "* If you wrote your grammar right, this should be covered. If this isn't covered, then you'll need to go back and change your grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ['timba', 'his', 'face', 'red', 'his', 'eye', 'black', 'in', 'winter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP\n",
      "    (N timba)\n",
      "    (NP\n",
      "      (Det his)\n",
      "      (NP\n",
      "        (N face)\n",
      "        (Adj red)\n",
      "        (NP\n",
      "          (Det his)\n",
      "          (NP (N eye) (Adj black) (NP (P in) (NP (N winter)))))))))\n"
     ]
    }
   ],
   "source": [
    "for tree in parser.parse(w):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Was your result in Questions 8 ambiguous?\n",
    "\n",
    "* Answer in markdown or raw text, no code necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "No, there was only one parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 10. How expressive is your language?\n",
    "\n",
    "* Answer in markdown or raw text, no code necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it has at least one recursive rule, it can generate an infinite number of sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Make the grammar more general by treating POS tags as the terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamarian_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> NP\n",
    "    NP  -> 'N' | 'N' NP | 'N' 'Adj' | 'CC' NP | 'P' NP | 'Det' NP | 'N' 'Adj' NP\n",
    "    \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. What is your set of POS tags?\n",
    "\n",
    "* show the list of strings (e.g., ['Adj', ...])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = ['Det', 'N', 'P', 'Adj', 'CC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Make a list for the POS tags that correspond to the sentence `s` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ['timba', 'his', 'face', 'red', 'his', 'eye', 'black', 'in', 'winter']\n",
    "p = ['N',  'Det', 'N', 'Adj', 'Det', 'N', 'Adj', 'P', 'N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Parse the sentence (represented as POS tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP N (NP Det (NP N Adj (NP Det (NP N Adj (NP P (NP N))))))))\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(tamarian_grammar)\n",
    "\n",
    "for tree in parser.parse(p):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit! Do all of the above questions again, but add the sentence:\n",
    "\n",
    "'The beast of Tanagra Usani his army Jakka when the walls fell'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Done!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================\n",
      "Assignment: A4 Linguistics\n",
      "OK, version v1.13.11\n",
      "=====================================================================\n",
      "\n",
      "\n",
      "Open the following URL:\n",
      "\n",
      "https://okpy.org/client/login/\n",
      "\n",
      "After logging in, copy the code from the web page and paste it into the box.\n",
      "Then press the \"Enter\" key on your keyboard.\n",
      "\n",
      "Paste your code here: fOkUqcCFEBXHUUWz4c2mQMBVBPei3G\n",
      "Successfully logged in as emanuelhernandez@u.boisestate.edu\n"
     ]
    }
   ],
   "source": [
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('a4.ok')\n",
    "ok.auth(inline=True, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_checkpoint();"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ok.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
