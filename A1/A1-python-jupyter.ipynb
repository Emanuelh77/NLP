{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1\n",
    "## 1. Computing with Language: Text and Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + 5 * 2 - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-953e01372b97>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-953e01372b97>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    1 +\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "1 +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Sense and Sensibility by Jane Austen 1811>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concordance\n",
    "shows us every occurrence of a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### similar\n",
    "shows a similar range of contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n"
     ]
    }
   ],
   "source": [
    "text1.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n"
     ]
    }
   ],
   "source": [
    "text2.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### common contexts\n",
    "allows us to examine just the contexts that are shared by two or more words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_pretty am_glad a_lucky is_pretty be_glad\n"
     ]
    }
   ],
   "source": [
    "text2.common_contexts([\"monstrous\",\"very\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_other\n"
     ]
    }
   ],
   "source": [
    "text1.common_contexts([\"quite\",\"some\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dispersion plot\n",
    "used to see frequency of a list of words since the very first time they were used in the text. Each stripe is a word and each row represents the entire text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text3.generate() this method is not available in NLTK 3.0 but will be in a later version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44764"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " ',)',\n",
       " '.',\n",
       " '.)',\n",
       " ':',\n",
       " ';',\n",
       " ';)',\n",
       " '?',\n",
       " '?)',\n",
       " 'A',\n",
       " 'Abel',\n",
       " 'Abelmizraim',\n",
       " 'Abidah',\n",
       " 'Abide',\n",
       " 'Abimael',\n",
       " 'Abimelech',\n",
       " 'Abr',\n",
       " 'Abrah',\n",
       " 'Abraham',\n",
       " 'Abram',\n",
       " 'Accad',\n",
       " 'Achbor',\n",
       " 'Adah',\n",
       " 'Adam',\n",
       " 'Adbeel',\n",
       " 'Admah',\n",
       " 'Adullamite',\n",
       " 'After',\n",
       " 'Aholibamah',\n",
       " 'Ahuzzath',\n",
       " 'Ajah',\n",
       " 'Akan',\n",
       " 'All',\n",
       " 'Allonbachuth',\n",
       " 'Almighty',\n",
       " 'Almodad',\n",
       " 'Also',\n",
       " 'Alvah',\n",
       " 'Alvan',\n",
       " 'Am',\n",
       " 'Amal',\n",
       " 'Amalek',\n",
       " 'Amalekites',\n",
       " 'Ammon',\n",
       " 'Amorite',\n",
       " 'Amorites',\n",
       " 'Amraphel',\n",
       " 'An',\n",
       " 'Anah',\n",
       " 'Anamim',\n",
       " 'And',\n",
       " 'Aner',\n",
       " 'Angel',\n",
       " 'Appoint',\n",
       " 'Aram',\n",
       " 'Aran',\n",
       " 'Ararat',\n",
       " 'Arbah',\n",
       " 'Ard',\n",
       " 'Are',\n",
       " 'Areli',\n",
       " 'Arioch',\n",
       " 'Arise',\n",
       " 'Arkite',\n",
       " 'Arodi',\n",
       " 'Arphaxad',\n",
       " 'Art',\n",
       " 'Arvadite',\n",
       " 'As',\n",
       " 'Asenath',\n",
       " 'Ashbel',\n",
       " 'Asher',\n",
       " 'Ashkenaz',\n",
       " 'Ashteroth',\n",
       " 'Ask',\n",
       " 'Asshur',\n",
       " 'Asshurim',\n",
       " 'Assyr',\n",
       " 'Assyria',\n",
       " 'At',\n",
       " 'Atad',\n",
       " 'Avith',\n",
       " 'Baalhanan',\n",
       " 'Babel',\n",
       " 'Bashemath',\n",
       " 'Be',\n",
       " 'Because',\n",
       " 'Becher',\n",
       " 'Bedad',\n",
       " 'Beeri',\n",
       " 'Beerlahairoi',\n",
       " 'Beersheba',\n",
       " 'Behold',\n",
       " 'Bela',\n",
       " 'Belah',\n",
       " 'Benam',\n",
       " 'Benjamin',\n",
       " 'Beno',\n",
       " 'Beor',\n",
       " 'Bera',\n",
       " 'Bered',\n",
       " 'Beriah',\n",
       " 'Bethel',\n",
       " 'Bethlehem',\n",
       " 'Bethuel',\n",
       " 'Beware',\n",
       " 'Bilhah',\n",
       " 'Bilhan',\n",
       " 'Binding',\n",
       " 'Birsha',\n",
       " 'Bless',\n",
       " 'Blessed',\n",
       " 'Both',\n",
       " 'Bow',\n",
       " 'Bozrah',\n",
       " 'Bring',\n",
       " 'But',\n",
       " 'Buz',\n",
       " 'By',\n",
       " 'Cain',\n",
       " 'Cainan',\n",
       " 'Calah',\n",
       " 'Calneh',\n",
       " 'Can',\n",
       " 'Cana',\n",
       " 'Canaan',\n",
       " 'Canaanite',\n",
       " 'Canaanites',\n",
       " 'Canaanitish',\n",
       " 'Caphtorim',\n",
       " 'Carmi',\n",
       " 'Casluhim',\n",
       " 'Cast',\n",
       " 'Cause',\n",
       " 'Chaldees',\n",
       " 'Chedorlaomer',\n",
       " 'Cheran',\n",
       " 'Cherubims',\n",
       " 'Chesed',\n",
       " 'Chezib',\n",
       " 'Come',\n",
       " 'Cursed',\n",
       " 'Cush',\n",
       " 'Damascus',\n",
       " 'Dan',\n",
       " 'Day',\n",
       " 'Deborah',\n",
       " 'Dedan',\n",
       " 'Deliver',\n",
       " 'Diklah',\n",
       " 'Din',\n",
       " 'Dinah',\n",
       " 'Dinhabah',\n",
       " 'Discern',\n",
       " 'Dishan',\n",
       " 'Dishon',\n",
       " 'Do',\n",
       " 'Dodanim',\n",
       " 'Dothan',\n",
       " 'Drink',\n",
       " 'Duke',\n",
       " 'Dumah',\n",
       " 'Earth',\n",
       " 'Ebal',\n",
       " 'Eber',\n",
       " 'Edar',\n",
       " 'Eden',\n",
       " 'Edom',\n",
       " 'Edomites',\n",
       " 'Egy',\n",
       " 'Egypt',\n",
       " 'Egyptia',\n",
       " 'Egyptian',\n",
       " 'Egyptians',\n",
       " 'Ehi',\n",
       " 'Elah',\n",
       " 'Elam',\n",
       " 'Elbethel',\n",
       " 'Eldaah',\n",
       " 'EleloheIsrael',\n",
       " 'Eliezer',\n",
       " 'Eliphaz',\n",
       " 'Elishah',\n",
       " 'Ellasar',\n",
       " 'Elon',\n",
       " 'Elparan',\n",
       " 'Emins',\n",
       " 'En',\n",
       " 'Enmishpat',\n",
       " 'Eno',\n",
       " 'Enoch',\n",
       " 'Enos',\n",
       " 'Ephah',\n",
       " 'Epher',\n",
       " 'Ephra',\n",
       " 'Ephraim',\n",
       " 'Ephrath',\n",
       " 'Ephron',\n",
       " 'Er',\n",
       " 'Erech',\n",
       " 'Eri',\n",
       " 'Es',\n",
       " 'Esau',\n",
       " 'Escape',\n",
       " 'Esek',\n",
       " 'Eshban',\n",
       " 'Eshcol',\n",
       " 'Ethiopia',\n",
       " 'Euphrat',\n",
       " 'Euphrates',\n",
       " 'Eve',\n",
       " 'Even',\n",
       " 'Every',\n",
       " 'Except',\n",
       " 'Ezbon',\n",
       " 'Ezer',\n",
       " 'Fear',\n",
       " 'Feed',\n",
       " 'Fifteen',\n",
       " 'Fill',\n",
       " 'For',\n",
       " 'Forasmuch',\n",
       " 'Forgive',\n",
       " 'From',\n",
       " 'Fulfil',\n",
       " 'G',\n",
       " 'Gad',\n",
       " 'Gaham',\n",
       " 'Galeed',\n",
       " 'Gatam',\n",
       " 'Gather',\n",
       " 'Gaza',\n",
       " 'Gentiles',\n",
       " 'Gera',\n",
       " 'Gerar',\n",
       " 'Gershon',\n",
       " 'Get',\n",
       " 'Gether',\n",
       " 'Gihon',\n",
       " 'Gilead',\n",
       " 'Girgashites',\n",
       " 'Girgasite',\n",
       " 'Give',\n",
       " 'Go',\n",
       " 'God',\n",
       " 'Gomer',\n",
       " 'Gomorrah',\n",
       " 'Goshen',\n",
       " 'Guni',\n",
       " 'Hadad',\n",
       " 'Hadar',\n",
       " 'Hadoram',\n",
       " 'Hagar',\n",
       " 'Haggi',\n",
       " 'Hai',\n",
       " 'Ham',\n",
       " 'Hamathite',\n",
       " 'Hamor',\n",
       " 'Hamul',\n",
       " 'Hanoch',\n",
       " 'Happy',\n",
       " 'Haran',\n",
       " 'Hast',\n",
       " 'Haste',\n",
       " 'Have',\n",
       " 'Havilah',\n",
       " 'Hazarmaveth',\n",
       " 'Hazezontamar',\n",
       " 'Hazo',\n",
       " 'He',\n",
       " 'Hear',\n",
       " 'Heaven',\n",
       " 'Heber',\n",
       " 'Hebrew',\n",
       " 'Hebrews',\n",
       " 'Hebron',\n",
       " 'Hemam',\n",
       " 'Hemdan',\n",
       " 'Here',\n",
       " 'Hereby',\n",
       " 'Heth',\n",
       " 'Hezron',\n",
       " 'Hiddekel',\n",
       " 'Hinder',\n",
       " 'Hirah',\n",
       " 'His',\n",
       " 'Hitti',\n",
       " 'Hittite',\n",
       " 'Hittites',\n",
       " 'Hivite',\n",
       " 'Hobah',\n",
       " 'Hori',\n",
       " 'Horite',\n",
       " 'Horites',\n",
       " 'How',\n",
       " 'Hul',\n",
       " 'Huppim',\n",
       " 'Husham',\n",
       " 'Hushim',\n",
       " 'Huz',\n",
       " 'I',\n",
       " 'If',\n",
       " 'In',\n",
       " 'Irad',\n",
       " 'Iram',\n",
       " 'Is',\n",
       " 'Isa',\n",
       " 'Isaac',\n",
       " 'Iscah',\n",
       " 'Ishbak',\n",
       " 'Ishmael',\n",
       " 'Ishmeelites',\n",
       " 'Ishuah',\n",
       " 'Isra',\n",
       " 'Israel',\n",
       " 'Issachar',\n",
       " 'Isui',\n",
       " 'It',\n",
       " 'Ithran',\n",
       " 'Jaalam',\n",
       " 'Jabal',\n",
       " 'Jabbok',\n",
       " 'Jac',\n",
       " 'Jachin',\n",
       " 'Jacob',\n",
       " 'Jahleel',\n",
       " 'Jahzeel',\n",
       " 'Jamin',\n",
       " 'Japhe',\n",
       " 'Japheth',\n",
       " 'Jared',\n",
       " 'Javan',\n",
       " 'Jebusite',\n",
       " 'Jebusites',\n",
       " 'Jegarsahadutha',\n",
       " 'Jehovahjireh',\n",
       " 'Jemuel',\n",
       " 'Jerah',\n",
       " 'Jetheth',\n",
       " 'Jetur',\n",
       " 'Jeush',\n",
       " 'Jezer',\n",
       " 'Jidlaph',\n",
       " 'Jimnah',\n",
       " 'Job',\n",
       " 'Jobab',\n",
       " 'Jokshan',\n",
       " 'Joktan',\n",
       " 'Jordan',\n",
       " 'Joseph',\n",
       " 'Jubal',\n",
       " 'Judah',\n",
       " 'Judge',\n",
       " 'Judith',\n",
       " 'Kadesh',\n",
       " 'Kadmonites',\n",
       " 'Karnaim',\n",
       " 'Kedar',\n",
       " 'Kedemah',\n",
       " 'Kemuel',\n",
       " 'Kenaz',\n",
       " 'Kenites',\n",
       " 'Kenizzites',\n",
       " 'Keturah',\n",
       " 'Kiriathaim',\n",
       " 'Kirjatharba',\n",
       " 'Kittim',\n",
       " 'Know',\n",
       " 'Kohath',\n",
       " 'Kor',\n",
       " 'Korah',\n",
       " 'LO',\n",
       " 'LORD',\n",
       " 'Laban',\n",
       " 'Lahairoi',\n",
       " 'Lamech',\n",
       " 'Lasha',\n",
       " 'Lay',\n",
       " 'Leah',\n",
       " 'Lehabim',\n",
       " 'Lest',\n",
       " 'Let',\n",
       " 'Letushim',\n",
       " 'Leummim',\n",
       " 'Levi',\n",
       " 'Lie',\n",
       " 'Lift',\n",
       " 'Lo',\n",
       " 'Look',\n",
       " 'Lot',\n",
       " 'Lotan',\n",
       " 'Lud',\n",
       " 'Ludim',\n",
       " 'Luz',\n",
       " 'Maachah',\n",
       " 'Machir',\n",
       " 'Machpelah',\n",
       " 'Madai',\n",
       " 'Magdiel',\n",
       " 'Magog',\n",
       " 'Mahalaleel',\n",
       " 'Mahalath',\n",
       " 'Mahanaim',\n",
       " 'Make',\n",
       " 'Malchiel',\n",
       " 'Male',\n",
       " 'Mam',\n",
       " 'Mamre',\n",
       " 'Man',\n",
       " 'Manahath',\n",
       " 'Manass',\n",
       " 'Manasseh',\n",
       " 'Mash',\n",
       " 'Masrekah',\n",
       " 'Massa',\n",
       " 'Matred',\n",
       " 'Me',\n",
       " 'Medan',\n",
       " 'Mehetabel',\n",
       " 'Mehujael',\n",
       " 'Melchizedek',\n",
       " 'Merari',\n",
       " 'Mesha',\n",
       " 'Meshech',\n",
       " 'Mesopotamia',\n",
       " 'Methusa',\n",
       " 'Methusael',\n",
       " 'Methuselah',\n",
       " 'Mezahab',\n",
       " 'Mibsam',\n",
       " 'Mibzar',\n",
       " 'Midian',\n",
       " 'Midianites',\n",
       " 'Milcah',\n",
       " 'Mishma',\n",
       " 'Mizpah',\n",
       " 'Mizraim',\n",
       " 'Mizz',\n",
       " 'Moab',\n",
       " 'Moabites',\n",
       " 'Moreh',\n",
       " 'Moreover',\n",
       " 'Moriah',\n",
       " 'Muppim',\n",
       " 'My',\n",
       " 'Naamah',\n",
       " 'Naaman',\n",
       " 'Nahath',\n",
       " 'Nahor',\n",
       " 'Naphish',\n",
       " 'Naphtali',\n",
       " 'Naphtuhim',\n",
       " 'Nay',\n",
       " 'Nebajoth',\n",
       " 'Neither',\n",
       " 'Night',\n",
       " 'Nimrod',\n",
       " 'Nineveh',\n",
       " 'Noah',\n",
       " 'Nod',\n",
       " 'Not',\n",
       " 'Now',\n",
       " 'O',\n",
       " 'Obal',\n",
       " 'Of',\n",
       " 'Oh',\n",
       " 'Ohad',\n",
       " 'Omar',\n",
       " 'On',\n",
       " 'Onam',\n",
       " 'Onan',\n",
       " 'Only',\n",
       " 'Ophir',\n",
       " 'Our',\n",
       " 'Out',\n",
       " 'Padan',\n",
       " 'Padanaram',\n",
       " 'Paran',\n",
       " 'Pass',\n",
       " 'Pathrusim',\n",
       " 'Pau',\n",
       " 'Peace',\n",
       " 'Peleg',\n",
       " 'Peniel',\n",
       " 'Penuel',\n",
       " 'Peradventure',\n",
       " 'Perizzit',\n",
       " 'Perizzite',\n",
       " 'Perizzites',\n",
       " 'Phallu',\n",
       " 'Phara',\n",
       " 'Pharaoh',\n",
       " 'Pharez',\n",
       " 'Phichol',\n",
       " 'Philistim',\n",
       " 'Philistines',\n",
       " 'Phut',\n",
       " 'Phuvah',\n",
       " 'Pildash',\n",
       " 'Pinon',\n",
       " 'Pison',\n",
       " 'Potiphar',\n",
       " 'Potipherah',\n",
       " 'Put',\n",
       " 'Raamah',\n",
       " 'Rachel',\n",
       " 'Rameses',\n",
       " 'Rebek',\n",
       " 'Rebekah',\n",
       " 'Rehoboth',\n",
       " 'Remain',\n",
       " 'Rephaims',\n",
       " 'Resen',\n",
       " 'Return',\n",
       " 'Reu',\n",
       " 'Reub',\n",
       " 'Reuben',\n",
       " 'Reuel',\n",
       " 'Reumah',\n",
       " 'Riphath',\n",
       " 'Rosh',\n",
       " 'Sabtah',\n",
       " 'Sabtech',\n",
       " 'Said',\n",
       " 'Salah',\n",
       " 'Salem',\n",
       " 'Samlah',\n",
       " 'Sarah',\n",
       " 'Sarai',\n",
       " 'Saul',\n",
       " 'Save',\n",
       " 'Say',\n",
       " 'Se',\n",
       " 'Seba',\n",
       " 'See',\n",
       " 'Seeing',\n",
       " 'Seir',\n",
       " 'Sell',\n",
       " 'Send',\n",
       " 'Sephar',\n",
       " 'Serah',\n",
       " 'Sered',\n",
       " 'Serug',\n",
       " 'Set',\n",
       " 'Seth',\n",
       " 'Shalem',\n",
       " 'Shall',\n",
       " 'Shalt',\n",
       " 'Shammah',\n",
       " 'Shaul',\n",
       " 'Shaveh',\n",
       " 'She',\n",
       " 'Sheba',\n",
       " 'Shebah',\n",
       " 'Shechem',\n",
       " 'Shed',\n",
       " 'Shel',\n",
       " 'Shelah',\n",
       " 'Sheleph',\n",
       " 'Shem',\n",
       " 'Shemeber',\n",
       " 'Shepho',\n",
       " 'Shillem',\n",
       " 'Shiloh',\n",
       " 'Shimron',\n",
       " 'Shinab',\n",
       " 'Shinar',\n",
       " 'Shobal',\n",
       " 'Should',\n",
       " 'Shuah',\n",
       " 'Shuni',\n",
       " 'Shur',\n",
       " 'Sichem',\n",
       " 'Siddim',\n",
       " 'Sidon',\n",
       " 'Simeon',\n",
       " 'Sinite',\n",
       " 'Sitnah',\n",
       " 'Slay',\n",
       " 'So',\n",
       " 'Sod',\n",
       " 'Sodom',\n",
       " 'Sojourn',\n",
       " 'Some',\n",
       " 'Spake',\n",
       " 'Speak',\n",
       " 'Spirit',\n",
       " 'Stand',\n",
       " 'Succoth',\n",
       " 'Surely',\n",
       " 'Swear',\n",
       " 'Syrian',\n",
       " 'Take',\n",
       " 'Tamar',\n",
       " 'Tarshish',\n",
       " 'Tebah',\n",
       " 'Tell',\n",
       " 'Tema',\n",
       " 'Teman',\n",
       " 'Temani',\n",
       " 'Terah',\n",
       " 'Thahash',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'Therefore',\n",
       " 'These',\n",
       " 'They',\n",
       " 'Thirty',\n",
       " 'This',\n",
       " 'Thorns',\n",
       " 'Thou',\n",
       " 'Thus',\n",
       " 'Thy',\n",
       " 'Tidal',\n",
       " 'Timna',\n",
       " 'Timnah',\n",
       " 'Timnath',\n",
       " 'Tiras',\n",
       " 'To',\n",
       " 'Togarmah',\n",
       " 'Tola',\n",
       " 'Tubal',\n",
       " 'Tubalcain',\n",
       " 'Twelve',\n",
       " 'Two',\n",
       " 'Unstable',\n",
       " 'Until',\n",
       " 'Unto',\n",
       " 'Up',\n",
       " 'Upon',\n",
       " 'Ur',\n",
       " 'Uz',\n",
       " 'Uzal',\n",
       " 'We',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Whence',\n",
       " 'Where',\n",
       " 'Whereas',\n",
       " 'Wherefore',\n",
       " 'Which',\n",
       " 'While',\n",
       " 'Who',\n",
       " 'Whose',\n",
       " 'Whoso',\n",
       " 'Why',\n",
       " 'Wilt',\n",
       " 'With',\n",
       " 'Woman',\n",
       " 'Ye',\n",
       " 'Yea',\n",
       " 'Yet',\n",
       " 'Zaavan',\n",
       " 'Zaphnathpaaneah',\n",
       " 'Zar',\n",
       " 'Zarah',\n",
       " 'Zeboiim',\n",
       " 'Zeboim',\n",
       " 'Zebul',\n",
       " 'Zebulun',\n",
       " 'Zemarite',\n",
       " 'Zepho',\n",
       " 'Zerah',\n",
       " 'Zibeon',\n",
       " 'Zidon',\n",
       " 'Zillah',\n",
       " 'Zilpah',\n",
       " 'Zimran',\n",
       " 'Ziphion',\n",
       " 'Zo',\n",
       " 'Zoar',\n",
       " 'Zohar',\n",
       " 'Zuzims',\n",
       " 'a',\n",
       " 'abated',\n",
       " 'abide',\n",
       " 'able',\n",
       " 'abode',\n",
       " 'abomination',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abroad',\n",
       " 'absent',\n",
       " 'abundantly',\n",
       " 'accept',\n",
       " 'accepted',\n",
       " 'according',\n",
       " 'acknowledged',\n",
       " 'activity',\n",
       " 'add',\n",
       " 'adder',\n",
       " 'afar',\n",
       " 'afflict',\n",
       " 'affliction',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'aga',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aileth',\n",
       " 'air',\n",
       " 'al',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'almon',\n",
       " 'alo',\n",
       " 'alone',\n",
       " 'aloud',\n",
       " 'also',\n",
       " 'altar',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angry',\n",
       " 'anguish',\n",
       " 'anointedst',\n",
       " 'anoth',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'any',\n",
       " 'anything',\n",
       " 'appe',\n",
       " 'appear',\n",
       " 'appeared',\n",
       " 'appease',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'aprons',\n",
       " 'archer',\n",
       " 'archers',\n",
       " 'are',\n",
       " 'arise',\n",
       " 'ark',\n",
       " 'armed',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arose',\n",
       " 'arrayed',\n",
       " 'art',\n",
       " 'artificer',\n",
       " 'as',\n",
       " 'ascending',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asketh',\n",
       " 'ass',\n",
       " 'assembly',\n",
       " 'asses',\n",
       " 'assigned',\n",
       " 'asswaged',\n",
       " 'at',\n",
       " 'attained',\n",
       " 'audience',\n",
       " 'avenged',\n",
       " 'aw',\n",
       " 'awaked',\n",
       " 'away',\n",
       " 'awoke',\n",
       " 'back',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bade',\n",
       " 'badest',\n",
       " 'badne',\n",
       " 'bak',\n",
       " 'bake',\n",
       " 'bakemeats',\n",
       " 'baker',\n",
       " 'bakers',\n",
       " 'balm',\n",
       " 'bands',\n",
       " 'bank',\n",
       " 'bare',\n",
       " 'barr',\n",
       " 'barren',\n",
       " 'basket',\n",
       " 'baskets',\n",
       " 'battle',\n",
       " 'bdellium',\n",
       " 'be',\n",
       " 'bear',\n",
       " 'beari',\n",
       " 'bearing',\n",
       " 'beast',\n",
       " 'beasts',\n",
       " 'beautiful',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'befall',\n",
       " 'befell',\n",
       " 'before',\n",
       " 'began',\n",
       " 'begat',\n",
       " 'beget',\n",
       " 'begettest',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begotten',\n",
       " 'beguiled',\n",
       " 'beheld',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'being',\n",
       " 'believed',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'beneath',\n",
       " 'bereaved',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'besought',\n",
       " 'best',\n",
       " 'betimes',\n",
       " 'better',\n",
       " 'between',\n",
       " 'betwixt',\n",
       " 'beyond',\n",
       " 'binding',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birthday',\n",
       " 'birthright',\n",
       " 'biteth',\n",
       " 'bitter',\n",
       " 'blame',\n",
       " 'blameless',\n",
       " 'blasted',\n",
       " 'bless',\n",
       " 'blessed',\n",
       " 'blesseth',\n",
       " 'blessi',\n",
       " 'blessing',\n",
       " 'blessings',\n",
       " 'blindness',\n",
       " 'blood',\n",
       " 'blossoms',\n",
       " 'bodies',\n",
       " 'boldly',\n",
       " 'bondman',\n",
       " 'bondmen',\n",
       " 'bondwoman',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'book',\n",
       " 'booths',\n",
       " 'border',\n",
       " 'borders',\n",
       " 'born',\n",
       " 'bosom',\n",
       " 'both',\n",
       " 'bottle',\n",
       " 'bou',\n",
       " 'boug',\n",
       " 'bough',\n",
       " 'bought',\n",
       " 'bound',\n",
       " 'bow',\n",
       " 'bowed',\n",
       " 'bowels',\n",
       " 'bowing',\n",
       " 'boys',\n",
       " 'bracelets',\n",
       " 'branches',\n",
       " 'brass',\n",
       " 'bre',\n",
       " 'breach',\n",
       " 'bread',\n",
       " 'breadth',\n",
       " 'break',\n",
       " 'breaketh',\n",
       " 'breaking',\n",
       " 'breasts',\n",
       " 'breath',\n",
       " 'breathed',\n",
       " 'breed',\n",
       " 'brethren',\n",
       " 'brick',\n",
       " 'brimstone',\n",
       " 'bring',\n",
       " 'brink',\n",
       " 'broken',\n",
       " 'brook',\n",
       " 'broth',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'bruise',\n",
       " 'budded',\n",
       " 'build',\n",
       " 'builded',\n",
       " 'built',\n",
       " 'bulls',\n",
       " 'bundle',\n",
       " 'bundles',\n",
       " 'burdens',\n",
       " 'buried',\n",
       " 'burn',\n",
       " 'burning',\n",
       " 'burnt',\n",
       " 'bury',\n",
       " 'buryingplace',\n",
       " 'business',\n",
       " 'but',\n",
       " 'butler',\n",
       " 'butlers',\n",
       " 'butlership',\n",
       " 'butter',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'cakes',\n",
       " 'calf',\n",
       " 'call',\n",
       " 'called',\n",
       " 'came',\n",
       " 'camel',\n",
       " 'camels',\n",
       " 'camest',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'canst',\n",
       " 'captain',\n",
       " 'captive',\n",
       " 'captives',\n",
       " 'carcases',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'cast',\n",
       " 'castles',\n",
       " 'catt',\n",
       " 'cattle',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'cave',\n",
       " 'cease',\n",
       " 'ceased',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chain',\n",
       " 'chamber',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'charge',\n",
       " 'charged',\n",
       " 'chariot',\n",
       " 'chariots',\n",
       " 'chesnut',\n",
       " 'chi',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childless',\n",
       " 'childr',\n",
       " 'children',\n",
       " 'chode',\n",
       " 'choice',\n",
       " 'chose',\n",
       " 'circumcis',\n",
       " 'circumcise',\n",
       " 'circumcised',\n",
       " 'citi',\n",
       " 'cities',\n",
       " 'city',\n",
       " 'clave',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'cleave',\n",
       " 'clo',\n",
       " 'closed',\n",
       " 'clothed',\n",
       " 'clothes',\n",
       " 'cloud',\n",
       " 'clusters',\n",
       " 'co',\n",
       " 'coat',\n",
       " 'coats',\n",
       " 'coffin',\n",
       " 'cold',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text3)) / len(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3.count(\"smote\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4643016433938312"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * text4.count('a') / len(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead of repeating these tidious operations, it's better to create functions for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text))/len(text)\n",
    "\n",
    "def percentage(count, total):\n",
    "    return 100*(count/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06230453042623537"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13477005109975562"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4643016433938312"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage(text4.count('a'), len(text4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A Closer Look at Python: Texts as Lists of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = ['Call', 'me', 'Ishmael', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_diversity(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2 = ['The', 'family', 'of', 'Dashwood', 'had', 'long','been', 'settled', 'in', 'Sussex', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'family',\n",
       " 'of',\n",
       " 'Dashwood',\n",
       " 'had',\n",
       " 'long',\n",
       " 'been',\n",
       " 'settled',\n",
       " 'in',\n",
       " 'Sussex',\n",
       " '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent3 = ['In', 'the', 'beginning', 'God', 'created', 'the','heaven', 'and', 'the', 'earth', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monty', 'Python', 'and', 'the', 'Holy', 'Grail']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['Monty', 'Python'] + ['and', 'the', 'Holy', 'Grail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent4 = ['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', 'and', 'of', 'the','House', 'of', 'Representatives', ':']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow',\n",
       " '-',\n",
       " 'Citizens',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Senate',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'House',\n",
       " 'of',\n",
       " 'Representatives',\n",
       " ':',\n",
       " 'Call',\n",
       " 'me',\n",
       " 'Ishmael',\n",
       " '.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4 + sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.', 'Some']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1.append(\"Some\")\n",
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awaken'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4[173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4.index('awaken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U86',\n",
       " 'thats',\n",
       " 'why',\n",
       " 'something',\n",
       " 'like',\n",
       " 'gamefly',\n",
       " 'is',\n",
       " 'so',\n",
       " 'good',\n",
       " 'because',\n",
       " 'you',\n",
       " 'can',\n",
       " 'actually',\n",
       " 'play',\n",
       " 'a',\n",
       " 'full',\n",
       " 'game',\n",
       " 'without',\n",
       " 'buying',\n",
       " 'it']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5[16715:16735]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " \"'\",\n",
       " 're',\n",
       " 'an',\n",
       " 'anarcho',\n",
       " '-',\n",
       " 'syndicalist',\n",
       " 'commune',\n",
       " '.',\n",
       " 'We',\n",
       " 'take',\n",
       " 'it',\n",
       " 'in',\n",
       " 'turns',\n",
       " 'to',\n",
       " 'act',\n",
       " 'as',\n",
       " 'a',\n",
       " 'sort',\n",
       " 'of',\n",
       " 'executive',\n",
       " 'officer',\n",
       " 'for',\n",
       " 'the',\n",
       " 'week']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text6[1600:1625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['word1', 'word2', 'word3', 'word4', 'word5','word6', 'word7', 'word8', 'word9', 'word10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word1'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word10'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-baa8b4ccd19d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sent[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent[5:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word6'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word7'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word8'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word1', 'word2', 'word3']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['among',\n",
       " 'the',\n",
       " 'merits',\n",
       " 'and',\n",
       " 'the',\n",
       " 'happiness',\n",
       " 'of',\n",
       " 'Elinor',\n",
       " 'and',\n",
       " 'Marianne',\n",
       " ',',\n",
       " 'let',\n",
       " 'it',\n",
       " 'not',\n",
       " 'be',\n",
       " 'ranked',\n",
       " 'as',\n",
       " 'the',\n",
       " 'least',\n",
       " 'considerable',\n",
       " ',',\n",
       " 'that',\n",
       " 'though',\n",
       " 'sisters',\n",
       " ',',\n",
       " 'and',\n",
       " 'living',\n",
       " 'almost',\n",
       " 'within',\n",
       " 'sight',\n",
       " 'of',\n",
       " 'each',\n",
       " 'other',\n",
       " ',',\n",
       " 'they',\n",
       " 'could',\n",
       " 'live',\n",
       " 'without',\n",
       " 'disagreement',\n",
       " 'between',\n",
       " 'themselves',\n",
       " ',',\n",
       " 'or',\n",
       " 'producing',\n",
       " 'coolness',\n",
       " 'between',\n",
       " 'their',\n",
       " 'husbands',\n",
       " '.',\n",
       " 'THE',\n",
       " 'END']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2[141525:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent[0]='First'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent[9] = 'Last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent[1:9] = ['Second','Third']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First', 'Second', 'Third', 'Last']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-9d73df3f8677>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sent[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = ['Call', 'me', 'Ishmael', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sent = ['Bravely', 'bold', 'Sir', 'Robin', ',', 'rode','forth', 'from', 'Camelot', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_phrase = my_sent[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bold', 'Sir', 'Robin']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "wOrDs = sorted(noun_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Robin', 'Sir', 'bold']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wOrDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-59-673e7f915d89>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-59-673e7f915d89>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    not = 'Camelot'\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "not = 'Camelot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19317"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Monty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mont'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MontyMonty'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty!'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name + '!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(['Monty', 'Python'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monty', 'Python']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Monty Python'.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Computing with Language: Simple Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "saying = ['After', 'all', 'is', 'said', 'and', 'done', 'more', 'is', 'said', 'than', 'done']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = set(saying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sorted(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['said', 'than']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frequency distributions\n",
    "tells us the frequency of each vocabulary item in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist1 = FreqDist(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19317 samples and 260819 outcomes>\n"
     ]
    }
   ],
   "source": [
    "print(fdist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 18713),\n",
       " ('the', 13721),\n",
       " ('.', 6862),\n",
       " ('of', 6536),\n",
       " ('and', 6024),\n",
       " ('a', 4569),\n",
       " ('to', 4542),\n",
       " (';', 4072),\n",
       " ('in', 3916),\n",
       " ('that', 2982),\n",
       " (\"'\", 2684),\n",
       " ('-', 2552),\n",
       " ('his', 2459),\n",
       " ('it', 2209),\n",
       " ('I', 2124),\n",
       " ('s', 1739),\n",
       " ('is', 1695),\n",
       " ('he', 1661),\n",
       " ('with', 1659),\n",
       " ('was', 1632),\n",
       " ('as', 1620),\n",
       " ('\"', 1478),\n",
       " ('all', 1462),\n",
       " ('for', 1414),\n",
       " ('this', 1280),\n",
       " ('!', 1269),\n",
       " ('at', 1231),\n",
       " ('by', 1137),\n",
       " ('but', 1113),\n",
       " ('not', 1103),\n",
       " ('--', 1070),\n",
       " ('him', 1058),\n",
       " ('from', 1052),\n",
       " ('be', 1030),\n",
       " ('on', 1005),\n",
       " ('so', 918),\n",
       " ('whale', 906),\n",
       " ('one', 889),\n",
       " ('you', 841),\n",
       " ('had', 767),\n",
       " ('have', 760),\n",
       " ('there', 715),\n",
       " ('But', 705),\n",
       " ('or', 697),\n",
       " ('were', 680),\n",
       " ('now', 646),\n",
       " ('which', 640),\n",
       " ('?', 637),\n",
       " ('me', 627),\n",
       " ('like', 624)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1['whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fdist1.plot(15, cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = set(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CIRCUMNAVIGATION',\n",
       " 'Physiognomically',\n",
       " 'apprehensiveness',\n",
       " 'cannibalistically',\n",
       " 'characteristically',\n",
       " 'circumnavigating',\n",
       " 'circumnavigation',\n",
       " 'circumnavigations',\n",
       " 'comprehensiveness',\n",
       " 'hermaphroditical',\n",
       " 'indiscriminately',\n",
       " 'indispensableness',\n",
       " 'irresistibleness',\n",
       " 'physiognomically',\n",
       " 'preternaturalness',\n",
       " 'responsibilities',\n",
       " 'simultaneousness',\n",
       " 'subterraneousness',\n",
       " 'supernaturalness',\n",
       " 'superstitiousness',\n",
       " 'uncomfortableness',\n",
       " 'uncompromisedness',\n",
       " 'undiscriminating',\n",
       " 'uninterpenetratingly']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_words = [w for w in V if len(w) > 15]\n",
    "sorted(long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#14-19teens',\n",
       " '#talkcity_adults',\n",
       " '((((((((((',\n",
       " '........',\n",
       " 'Question',\n",
       " 'actually',\n",
       " 'anything',\n",
       " 'computer',\n",
       " 'cute.-ass',\n",
       " 'everyone',\n",
       " 'football',\n",
       " 'innocent',\n",
       " 'listening',\n",
       " 'remember',\n",
       " 'seriously',\n",
       " 'something',\n",
       " 'together',\n",
       " 'tomorrow',\n",
       " 'watching']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist5 = FreqDist(text5)\n",
    "sorted(w for w in set(text5) if len(w) > 7 and fdist5[w] > 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocation\n",
    "is a sequence of words that occur together unusually often"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams\n",
    "word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('more', 'is'), ('is', 'said'), ('said', 'than'), ('than', 'done')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams(['more', 'is', 'said', 'than', 'done']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; four years; years ago; Federal\n",
      "Government; General Government; American people; Vice President; Old\n",
      "World; Almighty God; Fellow citizens; Chief Magistrate; Chief Justice;\n",
      "God bless; every citizen; Indian tribes; public debt; one another;\n",
      "foreign nations; political parties\n"
     ]
    }
   ],
   "source": [
    "text4.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would like; medium build; social drinker; quiet nights; non smoker;\n",
      "long term; age open; Would like; easy going; financially secure; fun\n",
      "times; similar interests; Age open; weekends away; poss rship; well\n",
      "presented; never married; single mum; permanent relationship; slim\n",
      "build\n"
     ]
    }
   ],
   "source": [
    "text8.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 11,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 10,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 12,\n",
       " 1,\n",
       " 9,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 13,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 11,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 10,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 10,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 12,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 13,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 11,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 11,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 14,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 13,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 11,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(w) for w in text1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19 samples and 260819 outcomes>\n"
     ]
    }
   ],
   "source": [
    "fdist = FreqDist(len(w) for w in text1)\n",
    "print(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({3: 50223, 1: 47933, 4: 42345, 2: 38513, 5: 26597, 6: 17111, 7: 14399, 8: 9966, 9: 6428, 10: 3528, ...})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 50223),\n",
       " (1, 47933),\n",
       " (4, 42345),\n",
       " (2, 38513),\n",
       " (5, 26597),\n",
       " (6, 17111),\n",
       " (7, 14399),\n",
       " (8, 9966),\n",
       " (9, 6428),\n",
       " (10, 3528),\n",
       " (11, 1873),\n",
       " (12, 1053),\n",
       " (13, 567),\n",
       " (14, 177),\n",
       " (15, 70),\n",
       " (16, 22),\n",
       " (17, 12),\n",
       " (18, 1),\n",
       " (20, 1)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50223"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19255882431878046"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.freq(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Back to Python: Making Decisions and Taking Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '61', 'old', ',', 'the', 'as', 'a', '29', '.']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent7 if len(w) < 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '61', 'old', ',', 'will', 'join', 'the', 'as', 'a', 'Nov.', '29', '.']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent7 if len(w) <= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['will', 'join', 'Nov.']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent7 if len(w) == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in sent7 if len(w) != 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comfortableness',\n",
       " 'honourableness',\n",
       " 'immutableness',\n",
       " 'indispensableness',\n",
       " 'indomitableness',\n",
       " 'intolerableness',\n",
       " 'palpableness',\n",
       " 'reasonableness',\n",
       " 'uncomfortableness']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w for w in set(text1) if w.endswith('ableness'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sovereignty', 'sovereignties', 'sovereignty']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(term for term in set(text4) if 'gnt' in term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'Aaaaaaaaah',\n",
       " 'Aaaaaaaah',\n",
       " 'Aaaaaah',\n",
       " 'Aaaah',\n",
       " 'Aaaaugh',\n",
       " 'Aaagh',\n",
       " 'Aaah',\n",
       " 'Aaauggh',\n",
       " 'Aaaugh',\n",
       " 'Aaauugh',\n",
       " 'Aagh',\n",
       " 'Aah',\n",
       " 'Aauuggghhh',\n",
       " 'Aauuugh',\n",
       " 'Aauuuuugh',\n",
       " 'Aauuuves',\n",
       " 'Action',\n",
       " 'Actually',\n",
       " 'African',\n",
       " 'Ages',\n",
       " 'Aggh',\n",
       " 'Agh',\n",
       " 'Ah',\n",
       " 'Ahh',\n",
       " 'Alice',\n",
       " 'All',\n",
       " 'Allo',\n",
       " 'Almighty',\n",
       " 'Alright',\n",
       " 'Am',\n",
       " 'Amen',\n",
       " 'An',\n",
       " 'Anarcho',\n",
       " 'And',\n",
       " 'Angnor',\n",
       " 'Anthrax',\n",
       " 'Antioch',\n",
       " 'Anybody',\n",
       " 'Anyway',\n",
       " 'Apples',\n",
       " 'Aramaic',\n",
       " 'Are',\n",
       " 'Arimathea',\n",
       " 'Armaments',\n",
       " 'Arthur',\n",
       " 'As',\n",
       " 'Ask',\n",
       " 'Assyria',\n",
       " 'At',\n",
       " 'Attila',\n",
       " 'Augh',\n",
       " 'Autumn',\n",
       " 'Auuuuuuuugh',\n",
       " 'Away',\n",
       " 'Ay',\n",
       " 'Ayy',\n",
       " 'B',\n",
       " 'Back',\n",
       " 'Bad',\n",
       " 'Badon',\n",
       " 'Battle',\n",
       " 'Be',\n",
       " 'Beast',\n",
       " 'Bedevere',\n",
       " 'Bedwere',\n",
       " 'Behold',\n",
       " 'Between',\n",
       " 'Beyond',\n",
       " 'Black',\n",
       " 'Bloody',\n",
       " 'Blue',\n",
       " 'Bon',\n",
       " 'Bones',\n",
       " 'Book',\n",
       " 'Bors',\n",
       " 'Brave',\n",
       " 'Bravely',\n",
       " 'Bravest',\n",
       " 'Bread',\n",
       " 'Bridge',\n",
       " 'Bring',\n",
       " 'Bristol',\n",
       " 'Britain',\n",
       " 'Britons',\n",
       " 'Brother',\n",
       " 'Build',\n",
       " 'Burn',\n",
       " 'But',\n",
       " 'By',\n",
       " 'C',\n",
       " 'Caerbannog',\n",
       " 'Camaaaaaargue',\n",
       " 'Camelot',\n",
       " 'Castle',\n",
       " 'Chapter',\n",
       " 'Charge',\n",
       " 'Chaste',\n",
       " 'Cherries',\n",
       " 'Chicken',\n",
       " 'Chickennn',\n",
       " 'Chop',\n",
       " 'Christ',\n",
       " 'Churches',\n",
       " 'Cider',\n",
       " 'Clark',\n",
       " 'Clear',\n",
       " 'Come',\n",
       " 'Concorde',\n",
       " 'Consult',\n",
       " 'Cornwall',\n",
       " 'Could',\n",
       " 'Course',\n",
       " 'Court',\n",
       " 'Crapper',\n",
       " 'Cut',\n",
       " 'Dappy',\n",
       " 'Death',\n",
       " 'Defeat',\n",
       " 'Dennis',\n",
       " 'Did',\n",
       " 'Didn',\n",
       " 'Dingo',\n",
       " 'Dis',\n",
       " 'Divine',\n",
       " 'Do',\n",
       " 'Doctor',\n",
       " 'Does',\n",
       " 'Don',\n",
       " 'Dragon',\n",
       " 'Dramatically',\n",
       " 'Ecky',\n",
       " 'Ector',\n",
       " 'Eee',\n",
       " 'Eh',\n",
       " 'Enchanter',\n",
       " 'England',\n",
       " 'English',\n",
       " 'Erbert',\n",
       " 'Ere',\n",
       " 'Erm',\n",
       " 'Eternal',\n",
       " 'European',\n",
       " 'Even',\n",
       " 'Every',\n",
       " 'Everything',\n",
       " 'Ewing',\n",
       " 'Exactly',\n",
       " 'Excalibur',\n",
       " 'Excuse',\n",
       " 'Explain',\n",
       " 'Far',\n",
       " 'Farewell',\n",
       " 'Father',\n",
       " 'Fetchez',\n",
       " 'Fiends',\n",
       " 'Fine',\n",
       " 'First',\n",
       " 'Firstly',\n",
       " 'Five',\n",
       " 'Follow',\n",
       " 'For',\n",
       " 'Forgive',\n",
       " 'Forward',\n",
       " 'Found',\n",
       " 'Four',\n",
       " 'France',\n",
       " 'Frank',\n",
       " 'French',\n",
       " 'Gable',\n",
       " 'Galahad',\n",
       " 'Gallahad',\n",
       " 'Gawain',\n",
       " 'Get',\n",
       " 'Go',\n",
       " 'God',\n",
       " 'Good',\n",
       " 'Gorge',\n",
       " 'Grail',\n",
       " 'Great',\n",
       " 'Greetings',\n",
       " 'Grenade',\n",
       " 'Guards',\n",
       " 'Guy',\n",
       " 'Ha',\n",
       " 'Hah',\n",
       " 'Hallo',\n",
       " 'Halt',\n",
       " 'Hand',\n",
       " 'Hang',\n",
       " 'Have',\n",
       " 'Haw',\n",
       " 'He',\n",
       " 'Hee',\n",
       " 'Heee',\n",
       " 'Heh',\n",
       " 'Hello',\n",
       " 'Help',\n",
       " 'Herbert',\n",
       " 'Here',\n",
       " 'Hey',\n",
       " 'Hic',\n",
       " 'Hill',\n",
       " 'Himself',\n",
       " 'His',\n",
       " 'Hiyaah',\n",
       " 'Hiyah',\n",
       " 'Hiyya',\n",
       " 'Hm',\n",
       " 'Hmm',\n",
       " 'Ho',\n",
       " 'Hoa',\n",
       " 'Hold',\n",
       " 'Holy',\n",
       " 'Honestly',\n",
       " 'Hoo',\n",
       " 'Hooray',\n",
       " 'How',\n",
       " 'Huh',\n",
       " 'Hurry',\n",
       " 'Huy',\n",
       " 'Huyah',\n",
       " 'Hya',\n",
       " 'Hyy',\n",
       " 'I',\n",
       " 'Idiom',\n",
       " 'Iesu',\n",
       " 'If',\n",
       " 'Iiiiives',\n",
       " 'Iiiives',\n",
       " 'In',\n",
       " 'Is',\n",
       " 'Isn',\n",
       " 'It',\n",
       " 'Ives',\n",
       " 'Jesus',\n",
       " 'Joseph',\n",
       " 'Just',\n",
       " 'Keep',\n",
       " 'King',\n",
       " 'Knight',\n",
       " 'Knights',\n",
       " 'Lady',\n",
       " 'Lake',\n",
       " 'Lancelot',\n",
       " 'Launcelot',\n",
       " 'Lead',\n",
       " 'Leaving',\n",
       " 'Let',\n",
       " 'Lie',\n",
       " 'Like',\n",
       " 'Listen',\n",
       " 'Loimbard',\n",
       " 'Look',\n",
       " 'Looks',\n",
       " 'Lord',\n",
       " 'Lucky',\n",
       " 'Make',\n",
       " 'Man',\n",
       " 'May',\n",
       " 'Maynard',\n",
       " 'Meanwhile',\n",
       " 'Mercea',\n",
       " 'Message',\n",
       " 'Midget',\n",
       " 'Mind',\n",
       " 'Mine',\n",
       " 'Mmm',\n",
       " 'Monsieur',\n",
       " 'More',\n",
       " 'Morning',\n",
       " 'Most',\n",
       " 'Mother',\n",
       " 'Mud',\n",
       " 'Must',\n",
       " 'My',\n",
       " 'N',\n",
       " 'Nador',\n",
       " 'Nay',\n",
       " 'Neee',\n",
       " 'Never',\n",
       " 'Ni',\n",
       " 'Nine',\n",
       " 'Ninepence',\n",
       " 'No',\n",
       " 'None',\n",
       " 'Not',\n",
       " 'Nothing',\n",
       " 'Now',\n",
       " 'Nu',\n",
       " 'O',\n",
       " 'Of',\n",
       " 'Off',\n",
       " 'Oh',\n",
       " 'Ohh',\n",
       " 'Old',\n",
       " 'Olfin',\n",
       " 'On',\n",
       " 'Once',\n",
       " 'One',\n",
       " 'Ooh',\n",
       " 'Oooh',\n",
       " 'Oooo',\n",
       " 'Oooohoohohooo',\n",
       " 'Oooooooh',\n",
       " 'Open',\n",
       " 'Or',\n",
       " 'Order',\n",
       " 'Other',\n",
       " 'Oui',\n",
       " 'Our',\n",
       " 'Over',\n",
       " 'Ow',\n",
       " 'Packing',\n",
       " 'Patsy',\n",
       " 'Pendragon',\n",
       " 'Peng',\n",
       " 'Perhaps',\n",
       " 'Peril',\n",
       " 'Picture',\n",
       " 'Pie',\n",
       " 'Piglet',\n",
       " 'Pin',\n",
       " 'Please',\n",
       " 'Practice',\n",
       " 'Prepare',\n",
       " 'Prince',\n",
       " 'Princess',\n",
       " 'Providence',\n",
       " 'Psalms',\n",
       " 'Pull',\n",
       " 'Pure',\n",
       " 'Put',\n",
       " 'Quick',\n",
       " 'Quickly',\n",
       " 'Quiet',\n",
       " 'Quite',\n",
       " 'Quoi',\n",
       " 'Rather',\n",
       " 'Really',\n",
       " 'Recently',\n",
       " 'Remove',\n",
       " 'Rheged',\n",
       " 'Ridden',\n",
       " 'Right',\n",
       " 'Riiight',\n",
       " 'Robin',\n",
       " 'Robinson',\n",
       " 'Roger',\n",
       " 'Round',\n",
       " 'Run',\n",
       " 'Running',\n",
       " 'S',\n",
       " 'Said',\n",
       " 'Saint',\n",
       " 'Saxons',\n",
       " 'Say',\n",
       " 'Schools',\n",
       " 'See',\n",
       " 'Seek',\n",
       " 'Shall',\n",
       " 'She',\n",
       " 'Shh',\n",
       " 'Shrubber',\n",
       " 'Shrubberies',\n",
       " 'Shut',\n",
       " 'Silence',\n",
       " 'Silly',\n",
       " 'Since',\n",
       " 'Sir',\n",
       " 'Skip',\n",
       " 'So',\n",
       " 'Sorry',\n",
       " 'Speak',\n",
       " 'Splendid',\n",
       " 'Spring',\n",
       " 'Stand',\n",
       " 'Stay',\n",
       " 'Steady',\n",
       " 'Stop',\n",
       " 'Summer',\n",
       " 'Supposing',\n",
       " 'Supreme',\n",
       " 'Surely',\n",
       " 'Swamp',\n",
       " 'Table',\n",
       " 'Tale',\n",
       " 'Tall',\n",
       " 'Tell',\n",
       " 'Thank',\n",
       " 'That',\n",
       " 'The',\n",
       " 'Thee',\n",
       " 'Then',\n",
       " 'There',\n",
       " 'Therefore',\n",
       " 'They',\n",
       " 'This',\n",
       " 'Those',\n",
       " 'Thou',\n",
       " 'Thpppppt',\n",
       " 'Thppppt',\n",
       " 'Thpppt',\n",
       " 'Thppt',\n",
       " 'Three',\n",
       " 'Throw',\n",
       " 'Thsss',\n",
       " 'Thursday',\n",
       " 'Thy',\n",
       " 'Til',\n",
       " 'Tim',\n",
       " 'Tis',\n",
       " 'To',\n",
       " 'Today',\n",
       " 'Together',\n",
       " 'Too',\n",
       " 'Torment',\n",
       " 'Tower',\n",
       " 'True',\n",
       " 'Try',\n",
       " 'Twenty',\n",
       " 'Two',\n",
       " 'U',\n",
       " 'Uh',\n",
       " 'Uhh',\n",
       " 'Ulk',\n",
       " 'Um',\n",
       " 'Umhm',\n",
       " 'Umm',\n",
       " 'Un',\n",
       " 'Unfortunately',\n",
       " 'Until',\n",
       " 'Use',\n",
       " 'Uther',\n",
       " 'Uugh',\n",
       " 'Uuh',\n",
       " 'Very',\n",
       " 'Victory',\n",
       " 'W',\n",
       " 'Waa',\n",
       " 'Wait',\n",
       " 'Walk',\n",
       " 'Wayy',\n",
       " 'We',\n",
       " 'Welcome',\n",
       " 'Well',\n",
       " 'What',\n",
       " 'When',\n",
       " 'Where',\n",
       " 'Which',\n",
       " 'Who',\n",
       " 'Whoa',\n",
       " 'Why',\n",
       " 'Will',\n",
       " 'Winston',\n",
       " 'Winter',\n",
       " 'With',\n",
       " 'Woa',\n",
       " 'Wood',\n",
       " 'Would',\n",
       " 'Y',\n",
       " 'Yapping',\n",
       " 'Yay',\n",
       " 'Yeaaah',\n",
       " 'Yeaah',\n",
       " 'Yeah',\n",
       " 'Yes',\n",
       " 'You',\n",
       " 'Your',\n",
       " 'Yup',\n",
       " 'Zoot']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(item for item in set(text6) if item.istitle())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29', '61']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(item for item in set(sent7) if item.isdigit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stock-index',\n",
       " 'index-arbitrage',\n",
       " 'index-fund',\n",
       " 'index-options',\n",
       " 'index-related',\n",
       " 'stock-index']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w for w in set(text7) if '-' in w and 'index' in w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abelmizraim',\n",
       " 'Allonbachuth',\n",
       " 'Beerlahairoi',\n",
       " 'Canaanitish',\n",
       " 'Chedorlaomer',\n",
       " 'Girgashites',\n",
       " 'Hazarmaveth',\n",
       " 'Hazezontamar',\n",
       " 'Ishmeelites',\n",
       " 'Jegarsahadutha',\n",
       " 'Jehovahjireh',\n",
       " 'Kirjatharba',\n",
       " 'Melchizedek',\n",
       " 'Mesopotamia',\n",
       " 'Peradventure',\n",
       " 'Philistines',\n",
       " 'Zaphnathpaaneah']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(wd for wd in set(text3) if wd.istitle() and len(wd) > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '.', '29', '61', 'Nov.', 'Pierre', 'Vinken']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w for w in set(sent7) if not w.islower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ancient',\n",
       " 'ceiling',\n",
       " 'conceit',\n",
       " 'conceited',\n",
       " 'conceive',\n",
       " 'conscience',\n",
       " 'conscientious',\n",
       " 'conscientiously',\n",
       " 'deceitful',\n",
       " 'deceive',\n",
       " 'deceived',\n",
       " 'deceiving',\n",
       " 'deficiencies',\n",
       " 'deficiency',\n",
       " 'deficient',\n",
       " 'delicacies',\n",
       " 'excellencies',\n",
       " 'fancied',\n",
       " 'insufficiency',\n",
       " 'insufficient',\n",
       " 'legacies',\n",
       " 'perceive',\n",
       " 'perceived',\n",
       " 'perceiving',\n",
       " 'prescience',\n",
       " 'prophecies',\n",
       " 'receipt',\n",
       " 'receive',\n",
       " 'received',\n",
       " 'receiving',\n",
       " 'society',\n",
       " 'species',\n",
       " 'sufficient',\n",
       " 'sufficiently',\n",
       " 'undeceive',\n",
       " 'undeceiving']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(t for t in set(text2) if 'cie' in t or 'cei' in t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 11,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 10,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 12,\n",
       " 1,\n",
       " 9,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 13,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 11,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 11,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 10,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 10,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 12,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 13,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 11,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 11,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 10,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 14,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 13,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 11,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(w) for w in text1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'MOBY',\n",
       " 'DICK',\n",
       " 'BY',\n",
       " 'HERMAN',\n",
       " 'MELVILLE',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'SUPPLIED',\n",
       " 'BY',\n",
       " 'A',\n",
       " 'LATE',\n",
       " 'CONSUMPTIVE',\n",
       " 'USHER',\n",
       " 'TO',\n",
       " 'A',\n",
       " 'GRAMMAR',\n",
       " 'SCHOOL',\n",
       " ')',\n",
       " 'THE',\n",
       " 'PALE',\n",
       " 'USHER',\n",
       " '--',\n",
       " 'THREADBARE',\n",
       " 'IN',\n",
       " 'COAT',\n",
       " ',',\n",
       " 'HEART',\n",
       " ',',\n",
       " 'BODY',\n",
       " ',',\n",
       " 'AND',\n",
       " 'BRAIN',\n",
       " ';',\n",
       " 'I',\n",
       " 'SEE',\n",
       " 'HIM',\n",
       " 'NOW',\n",
       " '.',\n",
       " 'HE',\n",
       " 'WAS',\n",
       " 'EVER',\n",
       " 'DUSTING',\n",
       " 'HIS',\n",
       " 'OLD',\n",
       " 'LEXICONS',\n",
       " 'AND',\n",
       " 'GRAMMARS',\n",
       " ',',\n",
       " 'WITH',\n",
       " 'A',\n",
       " 'QUEER',\n",
       " 'HANDKERCHIEF',\n",
       " ',',\n",
       " 'MOCKINGLY',\n",
       " 'EMBELLISHED',\n",
       " 'WITH',\n",
       " 'ALL',\n",
       " 'THE',\n",
       " 'GAY',\n",
       " 'FLAGS',\n",
       " 'OF',\n",
       " 'ALL',\n",
       " 'THE',\n",
       " 'KNOWN',\n",
       " 'NATIONS',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'WORLD',\n",
       " '.',\n",
       " 'HE',\n",
       " 'LOVED',\n",
       " 'TO',\n",
       " 'DUST',\n",
       " 'HIS',\n",
       " 'OLD',\n",
       " 'GRAMMARS',\n",
       " ';',\n",
       " 'IT',\n",
       " 'SOMEHOW',\n",
       " 'MILDLY',\n",
       " 'REMINDED',\n",
       " 'HIM',\n",
       " 'OF',\n",
       " 'HIS',\n",
       " 'MORTALITY',\n",
       " '.',\n",
       " '\"',\n",
       " 'WHILE',\n",
       " 'YOU',\n",
       " 'TAKE',\n",
       " 'IN',\n",
       " 'HAND',\n",
       " 'TO',\n",
       " 'SCHOOL',\n",
       " 'OTHERS',\n",
       " ',',\n",
       " 'AND',\n",
       " 'TO',\n",
       " 'TEACH',\n",
       " 'THEM',\n",
       " 'BY',\n",
       " 'WHAT',\n",
       " 'NAME',\n",
       " 'A',\n",
       " 'WHALE',\n",
       " '-',\n",
       " 'FISH',\n",
       " 'IS',\n",
       " 'TO',\n",
       " 'BE',\n",
       " 'CALLED',\n",
       " 'IN',\n",
       " 'OUR',\n",
       " 'TONGUE',\n",
       " 'LEAVING',\n",
       " 'OUT',\n",
       " ',',\n",
       " 'THROUGH',\n",
       " 'IGNORANCE',\n",
       " ',',\n",
       " 'THE',\n",
       " 'LETTER',\n",
       " 'H',\n",
       " ',',\n",
       " 'WHICH',\n",
       " 'ALMOST',\n",
       " 'ALONE',\n",
       " 'MAKETH',\n",
       " 'THE',\n",
       " 'SIGNIFICATION',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'WORD',\n",
       " ',',\n",
       " 'YOU',\n",
       " 'DELIVER',\n",
       " 'THAT',\n",
       " 'WHICH',\n",
       " 'IS',\n",
       " 'NOT',\n",
       " 'TRUE',\n",
       " '.\"',\n",
       " '--',\n",
       " 'HACKLUYT',\n",
       " '\"',\n",
       " 'WHALE',\n",
       " '.',\n",
       " '...',\n",
       " 'SW',\n",
       " '.',\n",
       " 'AND',\n",
       " 'DAN',\n",
       " '.',\n",
       " 'HVAL',\n",
       " '.',\n",
       " 'THIS',\n",
       " 'ANIMAL',\n",
       " 'IS',\n",
       " 'NAMED',\n",
       " 'FROM',\n",
       " 'ROUNDNESS',\n",
       " 'OR',\n",
       " 'ROLLING',\n",
       " ';',\n",
       " 'FOR',\n",
       " 'IN',\n",
       " 'DAN',\n",
       " '.',\n",
       " 'HVALT',\n",
       " 'IS',\n",
       " 'ARCHED',\n",
       " 'OR',\n",
       " 'VAULTED',\n",
       " '.\"',\n",
       " '--',\n",
       " 'WEBSTER',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'DICTIONARY',\n",
       " '\"',\n",
       " 'WHALE',\n",
       " '.',\n",
       " '...',\n",
       " 'IT',\n",
       " 'IS',\n",
       " 'MORE',\n",
       " 'IMMEDIATELY',\n",
       " 'FROM',\n",
       " 'THE',\n",
       " 'DUT',\n",
       " '.',\n",
       " 'AND',\n",
       " 'GER',\n",
       " '.',\n",
       " 'WALLEN',\n",
       " ';',\n",
       " 'A',\n",
       " '.',\n",
       " 'S',\n",
       " '.',\n",
       " 'WALW',\n",
       " '-',\n",
       " 'IAN',\n",
       " ',',\n",
       " 'TO',\n",
       " 'ROLL',\n",
       " ',',\n",
       " 'TO',\n",
       " 'WALLOW',\n",
       " '.\"',\n",
       " '--',\n",
       " 'RICHARDSON',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'DICTIONARY',\n",
       " 'KETOS',\n",
       " ',',\n",
       " 'GREEK',\n",
       " '.',\n",
       " 'CETUS',\n",
       " ',',\n",
       " 'LATIN',\n",
       " '.',\n",
       " 'WHOEL',\n",
       " ',',\n",
       " 'ANGLO',\n",
       " '-',\n",
       " 'SAXON',\n",
       " '.',\n",
       " 'HVALT',\n",
       " ',',\n",
       " 'DANISH',\n",
       " '.',\n",
       " 'WAL',\n",
       " ',',\n",
       " 'DUTCH',\n",
       " '.',\n",
       " 'HWAL',\n",
       " ',',\n",
       " 'SWEDISH',\n",
       " '.',\n",
       " 'WHALE',\n",
       " ',',\n",
       " 'ICELANDIC',\n",
       " '.',\n",
       " 'WHALE',\n",
       " ',',\n",
       " 'ENGLISH',\n",
       " '.',\n",
       " 'BALEINE',\n",
       " ',',\n",
       " 'FRENCH',\n",
       " '.',\n",
       " 'BALLENA',\n",
       " ',',\n",
       " 'SPANISH',\n",
       " '.',\n",
       " 'PEKEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " ',',\n",
       " 'FEGEE',\n",
       " '.',\n",
       " 'PEKEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " '-',\n",
       " 'NUEE',\n",
       " ',',\n",
       " 'ERROMANGOAN',\n",
       " '.',\n",
       " 'EXTRACTS',\n",
       " '(',\n",
       " 'SUPPLIED',\n",
       " 'BY',\n",
       " 'A',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'LIBRARIAN',\n",
       " ').',\n",
       " 'IT',\n",
       " 'WILL',\n",
       " 'BE',\n",
       " 'SEEN',\n",
       " 'THAT',\n",
       " 'THIS',\n",
       " 'MERE',\n",
       " 'PAINSTAKING',\n",
       " 'BURROWER',\n",
       " 'AND',\n",
       " 'GRUB',\n",
       " '-',\n",
       " 'WORM',\n",
       " 'OF',\n",
       " 'A',\n",
       " 'POOR',\n",
       " 'DEVIL',\n",
       " 'OF',\n",
       " 'A',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'SUB',\n",
       " 'APPEARS',\n",
       " 'TO',\n",
       " 'HAVE',\n",
       " 'GONE',\n",
       " 'THROUGH',\n",
       " 'THE',\n",
       " 'LONG',\n",
       " 'VATICANS',\n",
       " 'AND',\n",
       " 'STREET',\n",
       " '-',\n",
       " 'STALLS',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'EARTH',\n",
       " ',',\n",
       " 'PICKING',\n",
       " 'UP',\n",
       " 'WHATEVER',\n",
       " 'RANDOM',\n",
       " 'ALLUSIONS',\n",
       " 'TO',\n",
       " 'WHALES',\n",
       " 'HE',\n",
       " 'COULD',\n",
       " 'ANYWAYS',\n",
       " 'FIND',\n",
       " 'IN',\n",
       " 'ANY',\n",
       " 'BOOK',\n",
       " 'WHATSOEVER',\n",
       " ',',\n",
       " 'SACRED',\n",
       " 'OR',\n",
       " 'PROFANE',\n",
       " '.',\n",
       " 'THEREFORE',\n",
       " 'YOU',\n",
       " 'MUST',\n",
       " 'NOT',\n",
       " ',',\n",
       " 'IN',\n",
       " 'EVERY',\n",
       " 'CASE',\n",
       " 'AT',\n",
       " 'LEAST',\n",
       " ',',\n",
       " 'TAKE',\n",
       " 'THE',\n",
       " 'HIGGLEDY',\n",
       " '-',\n",
       " 'PIGGLEDY',\n",
       " 'WHALE',\n",
       " 'STATEMENTS',\n",
       " ',',\n",
       " 'HOWEVER',\n",
       " 'AUTHENTIC',\n",
       " ',',\n",
       " 'IN',\n",
       " 'THESE',\n",
       " 'EXTRACTS',\n",
       " ',',\n",
       " 'FOR',\n",
       " 'VERITABLE',\n",
       " 'GOSPEL',\n",
       " 'CETOLOGY',\n",
       " '.',\n",
       " 'FAR',\n",
       " 'FROM',\n",
       " 'IT',\n",
       " '.',\n",
       " 'AS',\n",
       " 'TOUCHING',\n",
       " 'THE',\n",
       " 'ANCIENT',\n",
       " 'AUTHORS',\n",
       " 'GENERALLY',\n",
       " ',',\n",
       " 'AS',\n",
       " 'WELL',\n",
       " 'AS',\n",
       " 'THE',\n",
       " 'POETS',\n",
       " 'HERE',\n",
       " 'APPEARING',\n",
       " ',',\n",
       " 'THESE',\n",
       " 'EXTRACTS',\n",
       " 'ARE',\n",
       " 'SOLELY',\n",
       " 'VALUABLE',\n",
       " 'OR',\n",
       " 'ENTERTAINING',\n",
       " ',',\n",
       " 'AS',\n",
       " 'AFFORDING',\n",
       " 'A',\n",
       " 'GLANCING',\n",
       " 'BIRD',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'EYE',\n",
       " 'VIEW',\n",
       " 'OF',\n",
       " 'WHAT',\n",
       " 'HAS',\n",
       " 'BEEN',\n",
       " 'PROMISCUOUSLY',\n",
       " 'SAID',\n",
       " ',',\n",
       " 'THOUGHT',\n",
       " ',',\n",
       " 'FANCIED',\n",
       " ',',\n",
       " 'AND',\n",
       " 'SUNG',\n",
       " 'OF',\n",
       " 'LEVIATHAN',\n",
       " ',',\n",
       " 'BY',\n",
       " 'MANY',\n",
       " 'NATIONS',\n",
       " 'AND',\n",
       " 'GENERATIONS',\n",
       " ',',\n",
       " 'INCLUDING',\n",
       " 'OUR',\n",
       " 'OWN',\n",
       " '.',\n",
       " 'SO',\n",
       " 'FARE',\n",
       " 'THEE',\n",
       " 'WELL',\n",
       " ',',\n",
       " 'POOR',\n",
       " 'DEVIL',\n",
       " 'OF',\n",
       " 'A',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'SUB',\n",
       " ',',\n",
       " 'WHOSE',\n",
       " 'COMMENTATOR',\n",
       " 'I',\n",
       " 'AM',\n",
       " '.',\n",
       " 'THOU',\n",
       " 'BELONGEST',\n",
       " 'TO',\n",
       " 'THAT',\n",
       " 'HOPELESS',\n",
       " ',',\n",
       " 'SALLOW',\n",
       " 'TRIBE',\n",
       " 'WHICH',\n",
       " 'NO',\n",
       " 'WINE',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'WORLD',\n",
       " 'WILL',\n",
       " 'EVER',\n",
       " 'WARM',\n",
       " ';',\n",
       " 'AND',\n",
       " 'FOR',\n",
       " 'WHOM',\n",
       " 'EVEN',\n",
       " 'PALE',\n",
       " 'SHERRY',\n",
       " 'WOULD',\n",
       " 'BE',\n",
       " 'TOO',\n",
       " 'ROSY',\n",
       " '-',\n",
       " 'STRONG',\n",
       " ';',\n",
       " 'BUT',\n",
       " 'WITH',\n",
       " 'WHOM',\n",
       " 'ONE',\n",
       " 'SOMETIMES',\n",
       " 'LOVES',\n",
       " 'TO',\n",
       " 'SIT',\n",
       " ',',\n",
       " 'AND',\n",
       " 'FEEL',\n",
       " 'POOR',\n",
       " '-',\n",
       " 'DEVILISH',\n",
       " ',',\n",
       " 'TOO',\n",
       " ';',\n",
       " 'AND',\n",
       " 'GROW',\n",
       " 'CONVIVIAL',\n",
       " 'UPON',\n",
       " 'TEARS',\n",
       " ';',\n",
       " 'AND',\n",
       " 'SAY',\n",
       " 'TO',\n",
       " 'THEM',\n",
       " 'BLUNTLY',\n",
       " ',',\n",
       " 'WITH',\n",
       " 'FULL',\n",
       " 'EYES',\n",
       " 'AND',\n",
       " 'EMPTY',\n",
       " 'GLASSES',\n",
       " ',',\n",
       " 'AND',\n",
       " 'IN',\n",
       " 'NOT',\n",
       " 'ALTOGETHER',\n",
       " 'UNPLEASANT',\n",
       " 'SADNESS',\n",
       " '--',\n",
       " 'GIVE',\n",
       " 'IT',\n",
       " 'UP',\n",
       " ',',\n",
       " 'SUB',\n",
       " '-',\n",
       " 'SUBS',\n",
       " '!',\n",
       " 'FOR',\n",
       " 'BY',\n",
       " 'HOW',\n",
       " 'MUCH',\n",
       " 'THE',\n",
       " 'MORE',\n",
       " 'PAINS',\n",
       " 'YE',\n",
       " 'TAKE',\n",
       " 'TO',\n",
       " 'PLEASE',\n",
       " 'THE',\n",
       " 'WORLD',\n",
       " ',',\n",
       " 'BY',\n",
       " 'SO',\n",
       " 'MUCH',\n",
       " 'THE',\n",
       " 'MORE',\n",
       " 'SHALL',\n",
       " 'YE',\n",
       " 'FOR',\n",
       " 'EVER',\n",
       " 'GO',\n",
       " 'THANKLESS',\n",
       " '!',\n",
       " 'WOULD',\n",
       " 'THAT',\n",
       " 'I',\n",
       " 'COULD',\n",
       " 'CLEAR',\n",
       " 'OUT',\n",
       " 'HAMPTON',\n",
       " 'COURT',\n",
       " 'AND',\n",
       " 'THE',\n",
       " 'TUILERIES',\n",
       " 'FOR',\n",
       " 'YE',\n",
       " '!',\n",
       " 'BUT',\n",
       " 'GULP',\n",
       " 'DOWN',\n",
       " 'YOUR',\n",
       " 'TEARS',\n",
       " 'AND',\n",
       " 'HIE',\n",
       " 'ALOFT',\n",
       " 'TO',\n",
       " 'THE',\n",
       " 'ROYAL',\n",
       " '-',\n",
       " 'MAST',\n",
       " 'WITH',\n",
       " 'YOUR',\n",
       " 'HEARTS',\n",
       " ';',\n",
       " 'FOR',\n",
       " 'YOUR',\n",
       " 'FRIENDS',\n",
       " 'WHO',\n",
       " 'HAVE',\n",
       " 'GONE',\n",
       " 'BEFORE',\n",
       " 'ARE',\n",
       " 'CLEARING',\n",
       " 'OUT',\n",
       " 'THE',\n",
       " 'SEVEN',\n",
       " '-',\n",
       " 'STORIED',\n",
       " 'HEAVENS',\n",
       " ',',\n",
       " 'AND',\n",
       " 'MAKING',\n",
       " 'REFUGEES',\n",
       " 'OF',\n",
       " 'LONG',\n",
       " '-',\n",
       " 'PAMPERED',\n",
       " 'GABRIEL',\n",
       " ',',\n",
       " 'MICHAEL',\n",
       " ',',\n",
       " 'AND',\n",
       " 'RAPHAEL',\n",
       " ',',\n",
       " 'AGAINST',\n",
       " 'YOUR',\n",
       " 'COMING',\n",
       " '.',\n",
       " 'HERE',\n",
       " 'YE',\n",
       " 'STRIKE',\n",
       " 'BUT',\n",
       " 'SPLINTERED',\n",
       " 'HEARTS',\n",
       " 'TOGETHER',\n",
       " '--',\n",
       " 'THERE',\n",
       " ',',\n",
       " 'YE',\n",
       " 'SHALL',\n",
       " 'STRIKE',\n",
       " 'UNSPLINTERABLE',\n",
       " 'GLASSES',\n",
       " '!',\n",
       " 'EXTRACTS',\n",
       " '.',\n",
       " '\"',\n",
       " 'AND',\n",
       " 'GOD',\n",
       " 'CREATED',\n",
       " 'GREAT',\n",
       " 'WHALES',\n",
       " '.\"',\n",
       " '--',\n",
       " 'GENESIS',\n",
       " '.',\n",
       " '\"',\n",
       " 'LEVIATHAN',\n",
       " 'MAKETH',\n",
       " 'A',\n",
       " 'PATH',\n",
       " 'TO',\n",
       " 'SHINE',\n",
       " 'AFTER',\n",
       " 'HIM',\n",
       " ';',\n",
       " 'ONE',\n",
       " 'WOULD',\n",
       " 'THINK',\n",
       " 'THE',\n",
       " 'DEEP',\n",
       " 'TO',\n",
       " 'BE',\n",
       " 'HOARY',\n",
       " '.\"',\n",
       " '--',\n",
       " 'JOB',\n",
       " '.',\n",
       " '\"',\n",
       " 'NOW',\n",
       " 'THE',\n",
       " 'LORD',\n",
       " 'HAD',\n",
       " 'PREPARED',\n",
       " 'A',\n",
       " 'GREAT',\n",
       " 'FISH',\n",
       " 'TO',\n",
       " 'SWALLOW',\n",
       " 'UP',\n",
       " 'JONAH',\n",
       " '.\"',\n",
       " '--',\n",
       " 'JONAH',\n",
       " '.',\n",
       " '\"',\n",
       " 'THERE',\n",
       " 'GO',\n",
       " 'THE',\n",
       " 'SHIPS',\n",
       " ';',\n",
       " 'THERE',\n",
       " 'IS',\n",
       " 'THAT',\n",
       " 'LEVIATHAN',\n",
       " 'WHOM',\n",
       " 'THOU',\n",
       " 'HAST',\n",
       " 'MADE',\n",
       " 'TO',\n",
       " 'PLAY',\n",
       " 'THEREIN',\n",
       " '.\"',\n",
       " '--',\n",
       " 'PSALMS',\n",
       " '.',\n",
       " '\"',\n",
       " 'IN',\n",
       " 'THAT',\n",
       " 'DAY',\n",
       " ',',\n",
       " 'THE',\n",
       " 'LORD',\n",
       " 'WITH',\n",
       " 'HIS',\n",
       " 'SORE',\n",
       " ',',\n",
       " 'AND',\n",
       " 'GREAT',\n",
       " ',',\n",
       " 'AND',\n",
       " 'STRONG',\n",
       " 'SWORD',\n",
       " ',',\n",
       " 'SHALL',\n",
       " 'PUNISH',\n",
       " 'LEVIATHAN',\n",
       " 'THE',\n",
       " 'PIERCING',\n",
       " 'SERPENT',\n",
       " ',',\n",
       " 'EVEN',\n",
       " 'LEVIATHAN',\n",
       " 'THAT',\n",
       " 'CROOKED',\n",
       " 'SERPENT',\n",
       " ';',\n",
       " 'AND',\n",
       " 'HE',\n",
       " 'SHALL',\n",
       " 'SLAY',\n",
       " 'THE',\n",
       " 'DRAGON',\n",
       " 'THAT',\n",
       " 'IS',\n",
       " 'IN',\n",
       " 'THE',\n",
       " 'SEA',\n",
       " '.\"',\n",
       " '--',\n",
       " 'ISAIAH',\n",
       " '\"',\n",
       " 'AND',\n",
       " 'WHAT',\n",
       " 'THING',\n",
       " 'SOEVER',\n",
       " 'BESIDES',\n",
       " 'COMETH',\n",
       " 'WITHIN',\n",
       " 'THE',\n",
       " 'CHAOS',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'MONSTER',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'MOUTH',\n",
       " ',',\n",
       " 'BE',\n",
       " 'IT',\n",
       " 'BEAST',\n",
       " ',',\n",
       " 'BOAT',\n",
       " ',',\n",
       " 'OR',\n",
       " 'STONE',\n",
       " ',',\n",
       " 'DOWN',\n",
       " 'IT',\n",
       " 'GOES',\n",
       " 'ALL',\n",
       " 'INCONTINENTLY',\n",
       " 'THAT',\n",
       " 'FOUL',\n",
       " 'GREAT',\n",
       " 'SWALLOW',\n",
       " 'OF',\n",
       " 'HIS',\n",
       " ',',\n",
       " 'AND',\n",
       " 'PERISHETH',\n",
       " 'IN',\n",
       " 'THE',\n",
       " 'BOTTOMLESS',\n",
       " 'GULF',\n",
       " 'OF',\n",
       " 'HIS',\n",
       " 'PAUNCH',\n",
       " '.\"',\n",
       " '--',\n",
       " 'HOLLAND',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'PLUTARCH',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'MORALS',\n",
       " '.',\n",
       " '\"',\n",
       " 'THE',\n",
       " 'INDIAN',\n",
       " 'SEA',\n",
       " 'BREEDETH',\n",
       " 'THE',\n",
       " 'MOST',\n",
       " 'AND',\n",
       " 'THE',\n",
       " 'BIGGEST',\n",
       " 'FISHES',\n",
       " 'THAT',\n",
       " 'ARE',\n",
       " ':',\n",
       " 'AMONG',\n",
       " 'WHICH',\n",
       " 'THE',\n",
       " 'WHALES',\n",
       " 'AND',\n",
       " 'WHIRLPOOLES',\n",
       " 'CALLED',\n",
       " 'BALAENE',\n",
       " ',',\n",
       " 'TAKE',\n",
       " 'UP',\n",
       " 'AS',\n",
       " 'MUCH',\n",
       " 'IN',\n",
       " 'LENGTH',\n",
       " 'AS',\n",
       " 'FOUR',\n",
       " 'ACRES',\n",
       " 'OR',\n",
       " 'ARPENS',\n",
       " 'OF',\n",
       " 'LAND',\n",
       " '.\"',\n",
       " '--',\n",
       " 'HOLLAND',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'PLINY',\n",
       " '.',\n",
       " '\"',\n",
       " 'SCARCELY',\n",
       " 'HAD',\n",
       " 'WE',\n",
       " 'PROCEEDED',\n",
       " 'TWO',\n",
       " 'DAYS',\n",
       " 'ON',\n",
       " 'THE',\n",
       " 'SEA',\n",
       " ',',\n",
       " 'WHEN',\n",
       " 'ABOUT',\n",
       " 'SUNRISE',\n",
       " 'A',\n",
       " 'GREAT',\n",
       " 'MANY',\n",
       " 'WHALES',\n",
       " 'AND',\n",
       " 'OTHER',\n",
       " 'MONSTERS',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'SEA',\n",
       " ',',\n",
       " 'APPEARED',\n",
       " '.',\n",
       " 'AMONG',\n",
       " 'THE',\n",
       " 'FORMER',\n",
       " ',',\n",
       " 'ONE',\n",
       " 'WAS',\n",
       " 'OF',\n",
       " 'A',\n",
       " 'MOST',\n",
       " 'MONSTROUS',\n",
       " 'SIZE',\n",
       " '.',\n",
       " '...',\n",
       " 'THIS',\n",
       " 'CAME',\n",
       " 'TOWARDS',\n",
       " 'US',\n",
       " ',',\n",
       " 'OPEN',\n",
       " '-',\n",
       " 'MOUTHED',\n",
       " ',',\n",
       " 'RAISING',\n",
       " 'THE',\n",
       " 'WAVES',\n",
       " 'ON',\n",
       " 'ALL',\n",
       " 'SIDES',\n",
       " ',',\n",
       " 'AND',\n",
       " 'BEATING',\n",
       " 'THE',\n",
       " 'SEA',\n",
       " 'BEFORE',\n",
       " 'HIM',\n",
       " 'INTO',\n",
       " 'A',\n",
       " 'FOAM',\n",
       " '.\"',\n",
       " '--',\n",
       " 'TOOKE',\n",
       " \"'\",\n",
       " 'S',\n",
       " 'LUCIAN',\n",
       " '.',\n",
       " '\"',\n",
       " 'THE',\n",
       " 'TRUE',\n",
       " 'HISTORY',\n",
       " '.\"',\n",
       " '\"',\n",
       " 'HE',\n",
       " 'VISITED',\n",
       " 'THIS',\n",
       " 'COUNTRY',\n",
       " 'ALSO',\n",
       " 'WITH',\n",
       " 'A',\n",
       " 'VIEW',\n",
       " 'OF',\n",
       " 'CATCHING',\n",
       " 'HORSE',\n",
       " '-',\n",
       " 'WHALES',\n",
       " ',',\n",
       " 'WHICH',\n",
       " 'HAD',\n",
       " 'BONES',\n",
       " 'OF',\n",
       " 'VERY',\n",
       " 'GREAT',\n",
       " 'VALUE',\n",
       " 'FOR',\n",
       " 'THEIR',\n",
       " 'TEETH',\n",
       " ',',\n",
       " 'OF',\n",
       " 'WHICH',\n",
       " 'HE',\n",
       " 'BROUGHT',\n",
       " 'SOME',\n",
       " 'TO',\n",
       " 'THE',\n",
       " 'KING',\n",
       " '.',\n",
       " '...',\n",
       " 'THE',\n",
       " 'BEST',\n",
       " 'WHALES',\n",
       " 'WERE',\n",
       " 'CATCHED',\n",
       " 'IN',\n",
       " 'HIS',\n",
       " 'OWN',\n",
       " 'COUNTRY',\n",
       " ',',\n",
       " 'OF',\n",
       " 'WHICH',\n",
       " 'SOME',\n",
       " 'WERE',\n",
       " 'FORTY',\n",
       " '-',\n",
       " 'EIGHT',\n",
       " ',',\n",
       " 'SOME',\n",
       " 'FIFTY',\n",
       " 'YARDS',\n",
       " 'LONG',\n",
       " '.',\n",
       " 'HE',\n",
       " ...]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.upper() for w in text1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19317"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17231"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(word.lower() for word in text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16948"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(word.lower() for word in text1 if word.isalpha()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word length is less than 5\n"
     ]
    }
   ],
   "source": [
    "if len(word) < 5:\n",
    "    print('word length is less than 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(word) >= 5:\n",
    "    print('word length is greater than or equal to 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call\n",
      "me\n",
      "Ishmael\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for word in ['Call', 'me', 'Ishmael', '.']:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = ['Call', 'me', 'Ishmael', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call\n",
      "Ishmael\n"
     ]
    }
   ],
   "source": [
    "for xyzzy in sent1:\n",
    "    if xyzzy.endswith('l'):\n",
    "        print(xyzzy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call is a titlecase word\n",
      "me is a lowercase word\n",
      "Ishmael is a titlecase word\n",
      ". is punctuation\n"
     ]
    }
   ],
   "source": [
    "for token in sent1:\n",
    "    if token.islower():\n",
    "        print(token, 'is a lowercase word')\n",
    "    elif token.istitle():\n",
    "        print(token, 'is a titlecase word')\n",
    "    else:\n",
    "        print(token, 'is punctuation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4\n",
    "## 4.1 Back to the Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = 'Monty'\n",
    "bar = foo\n",
    "foo = 'Python'\n",
    "bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monty', 'Bodkin']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = ['Monty', 'Python']\n",
    "bar = foo\n",
    "foo[1] = 'Bodkin'\n",
    "bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "both foo and bar list objects are referencing the same location in the computer's memory, updating foo will also modify bar and viceversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], []]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty = []\n",
    "nested = [empty, empty, empty]\n",
    "nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Python'], ['Python']]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested[1].append('Python')\n",
    "nested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what happened previously is that each of the three items is actually just a reference to one and the same list in memory, in this case is `empty`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Monty'], ['Python']]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested = [[]] * 3\n",
    "nested[1].append('Python')\n",
    "nested[1] = ['Monty']\n",
    "nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 5\n",
    "python = ['Python']\n",
    "snake_nest = [python] * size\n",
    "snake_nest[0] == snake_nest[1] == snake_nest[2] == snake_nest[3] == snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest[0] is snake_nest[1] is snake_nest[2] is snake_nest[3] is snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Python'], ['Python'], ['Python'], ['Python'], ['Python']]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "position = random.choice(range(size))\n",
    "snake_nest[position] = ['Python']\n",
    "snake_nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest[0] == snake_nest[1] == snake_nest[2] == snake_nest[3] == snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snake_nest[0] is snake_nest[1] is snake_nest[2] is snake_nest[3] is snake_nest[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2221707572104, 2221707572104, 2221707572104, 2221707572104, 2221727278984]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[id(snake) for snake in snake_nest] #the fifth element has a different object identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "['dog']\n"
     ]
    }
   ],
   "source": [
    "mixed = ['cat', '', ['dog'], []]\n",
    "for element in mixed:\n",
    "    if element:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**the if-statement evaluates a nonempty string or list as true and an empty string/list as false**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "animals = ['cat', 'dog']\n",
    "if 'cat' in animals:\n",
    "    print(1)\n",
    "elif 'dog' in animals:\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['No', 'good', 'fish', 'goes', 'anywhere', 'without', 'a', 'porpoise', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(len(w) > 4 for w in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(len(w) > 4 for w in sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('walk', 'fem', 3)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 'walk', 'fem', 3\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fem', 3)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('t', 'the', 'turned')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = 'I turned off the spectroroute'\n",
    "text = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "pair = (6, 'turned')\n",
    "raw[2], text[3], pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ute', ['off', 'the', 'spectroroute'], (6, 'turned'))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[-3:], text[-3:], pair[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 5, 2)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw), len(text), len(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for item in s ----------> iterate over the items of s  \n",
    "for item in sorted(s) ----------> iterate over the items of s in order  \n",
    "for item in set(s) ----------> iterate over unique elements of s  \n",
    "for item in reversed(s) ----------> iterate over elements of s in reverse  \n",
    "for item in set(s).difference(t) ----------> iterate over elements of s not in t  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',', '.', 'Red', 'lorry', 'red', 'yellow']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = 'Red lorry, yellow lorry, red lorry, yellow lorry.'\n",
    "text = nltk.word_tokenize(raw)\n",
    "fdist = nltk.FreqDist(text)\n",
    "sorted(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red: 1; lorry: 4; ,: 3; yellow: 2; red: 1; .: 1; "
     ]
    }
   ],
   "source": [
    "for key in fdist:\n",
    "    print(key + ':', fdist[key], end='; ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'turned', 'the', 'spectroroute', 'off']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "words[2], words[3], words[4] = words[3], words[4], words[2]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = words[2]\n",
    "words[2] = words[3]\n",
    "words[3] = words[4]\n",
    "words[4] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x205332fa708>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "tags = ['noun', 'verb', 'prep', 'det', 'noun']\n",
    "zip(words, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'noun'),\n",
       " ('turned', 'verb'),\n",
       " ('off', 'prep'),\n",
       " ('the', 'det'),\n",
       " ('spectroroute', 'noun')]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(words, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'I'), (1, 'turned'), (2, 'off'), (3, 'the'), (4, 'spectroroute')]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.corpus.nps_chat.words()\n",
    "cut = int(0.9*len(text))\n",
    "training_data, test_data = text[:cut], text[cut:]\n",
    "text == training_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data) / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I off the turned spectroroute'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = 'I turned off the spectroroute'.split()\n",
    "wordlens = [(len(word), word) for word in words]\n",
    "wordlens.sort()\n",
    "' '.join(w for (_, w) in wordlens) #the underscore is used to indicate that the variable wont be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = [\n",
    "    ('the', 'det', ['Di:', 'D@']),\n",
    "    ('off', 'prep', ['Qf', 'O:f'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon.sort()\n",
    "lexicon[1] = ('turned', 'VBD', ['t3:nd', 't3`nd'])\n",
    "del lexicon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\"When I use a word,\" Humpty Dumpty said in rather a scornful tone,\"it means just what I choose it to mean - neither more nor less.\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['``',\n",
       " 'when',\n",
       " 'i',\n",
       " 'use',\n",
       " 'a',\n",
       " 'word',\n",
       " ',',\n",
       " \"''\",\n",
       " 'humpty',\n",
       " 'dumpty',\n",
       " 'said',\n",
       " 'in',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'scornful',\n",
       " 'tone',\n",
       " ',',\n",
       " \"''\",\n",
       " 'it',\n",
       " 'means',\n",
       " 'just',\n",
       " 'what',\n",
       " 'i',\n",
       " 'choose',\n",
       " 'it',\n",
       " 'to',\n",
       " 'mean',\n",
       " '-',\n",
       " 'neither',\n",
       " 'more',\n",
       " 'nor',\n",
       " 'less',\n",
       " '.',\n",
       " \"''\"]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lower() for w in nltk.word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([w.lower() for w in nltk.word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(w.lower() for w in nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Questions of Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```if (len(syllables) > 4 and len(syllables[2]) == 3 and\n",
    "    syllables[2][2] in [aeiou] and syllables[2][3] == syllables[1][3]):\n",
    "    process(syllables)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```if len(syllables) > 4 and len(syllables[2]) == 3 and \\\n",
    "    syllables[2][2] in [aeiou] and syllables[2][3] == syllables[1][3]:\n",
    "    process(syllables)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.corpus.brown.words(categories='news')\n",
    "count = 0\n",
    "total = 0\n",
    "for token in tokens:\n",
    "    count += 1\n",
    "    total += len(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.401545438271973"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.401545438271973\n"
     ]
    }
   ],
   "source": [
    "total = sum(len(t) for t in tokens) #creating a generator of lenghts and summing them up\n",
    "print(total/len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```word_list = []\n",
    "i = 0\n",
    "while i < len(tokens):\n",
    "    j = 0\n",
    "    while j < len(word_list) and word_list[j] <= tokens[i]:\n",
    "        j += 1\n",
    "    if j == 0 or tokens[i] != word_list[j-1]:\n",
    "        word_list.insert(j, tokens[i])\n",
    "    i += 1```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = sorted(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1   5.40% the\n",
      "  2  10.42% ,\n",
      "  3  14.67% .\n",
      "  4  17.78% of\n",
      "  5  20.19% and\n",
      "  6  22.40% to\n",
      "  7  24.29% a\n",
      "  8  25.97% in\n"
     ]
    }
   ],
   "source": [
    "fd = nltk.FreqDist(nltk.corpus.brown.words())\n",
    "cumulative = 0.0\n",
    "most_common_words = [word for (word, count) in fd.most_common()]\n",
    "for rank, word in enumerate(most_common_words):\n",
    "    cumulative += fd.freq(word)\n",
    "    print(\"%3d %6.2f%% %s\" % (rank+1, cumulative*100, word)) # %% to literally represent a percent sign\n",
    "    if cumulative > 0.25:\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unextinguishable'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = nltk.corpus.gutenberg.words('milton-paradise.txt')\n",
    "longest = ''\n",
    "for word in text:\n",
    "    if len(word) > len(longest):\n",
    "        longest = word\n",
    "longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unextinguishable',\n",
       " 'transubstantiate',\n",
       " 'inextinguishable',\n",
       " 'incomprehensible']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = max(len(word) for word in text)\n",
    "[word for word in text if len(word) == maxlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'dog', 'gave'],\n",
       " ['dog', 'gave', 'John'],\n",
       " ['gave', 'John', 'the'],\n",
       " ['John', 'the', 'newspaper']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "n = 3\n",
    "[sent[i:i+n] for i in range(len(sent)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[set(), set(), set(), set(), set(), set(), set()],\n",
      " [set(), set(), set(), set(), set(), set(), set()],\n",
      " [set(), set(), set(), set(), set(), {'Alice'}, set()]]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "m, n = 3, 7\n",
    "array = [[set() for i in range(n)] for j in range(m)]\n",
    "array[2][5].add('Alice')\n",
    "pprint.pprint(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{7}, {7}, {7}, {7}, {7}, {7}, {7}],\n",
      " [{7}, {7}, {7}, {7}, {7}, {7}, {7}],\n",
      " [{7}, {7}, {7}, {7}, {7}, {7}, {7}]]\n"
     ]
    }
   ],
   "source": [
    "array = [[set()] * n] * m\n",
    "array[2][5].add(7)\n",
    "pprint.pprint(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_text(file):\n",
    "    \"\"\"Read text from a file, normalizing whitespace and stripping HTML markup.\"\"\"\n",
    "    text = open(file).read()\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python Monty Python Monty Python'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repeat(msg, num):\n",
    "    return ' '.join([msg] * num)\n",
    "monty = 'Monty Python'\n",
    "repeat(monty, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def monty():\n",
    "    return \"Monty Python\"\n",
    "monty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python Monty Python Monty Python'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat(monty(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Monty Python Monty Python Monty Python'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat(\"Monty Python\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sort1(mylist):      # good: modifies its argument, no return value\n",
    "    mylist.sort()\n",
    "def my_sort2(mylist):      # good: doesn't touch its argument, returns value\n",
    "    return sorted(mylist)\n",
    "def my_sort3(mylist):      # bad: modifies its argument and also returns it\n",
    "    mylist.sort()\n",
    "    return mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_up(word, properties):\n",
    "    word = 'lolcat'\n",
    "    properties.append('noun')\n",
    "    properties = 5\n",
    "w = ''\n",
    "p = []\n",
    "set_up(w,p)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noun']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = ''\n",
    "word = w\n",
    "word = 'lolcat'\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noun']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = []\n",
    "properties = p\n",
    "properties.append('noun')\n",
    "properties = 5\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(word):\n",
    "    if word in ['a', 'the', 'all']:\n",
    "        return 'det'\n",
    "    else:\n",
    "        return 'noun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'det'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag('knight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag([\"'Tis'\",\"but\",'a','scratch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(word):\n",
    "    assert isinstance(word, basestring), \"argument to tag() must be a string\"\n",
    "    if word in ['a', 'the', 'all']:\n",
    "        return 'det'\n",
    "    else:\n",
    "        return 'noun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def freq_words(url, freqdist, n):\n",
    "    html = request.urlopen(url).read().decode('utf8')\n",
    "    raw = BeautifulSoup(html).get_text()\n",
    "    for word in nltk.word_tokenize(raw):\n",
    "        freqdist[word.lower()] += 1\n",
    "    result = []\n",
    "    for word, count in freqdist.most_common(n):\n",
    "        result = result + [word]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'the', \"''\", 'of', 'and', 'shall', '.', 'be', 'to', ';', ':', 'in', 'states', 'or', ':1', 'a', 'united', 'state', 'by', 'for', '{', '}', '(', ')', 'any', 'on', 'all', 'which', 'president', 'may']\n"
     ]
    }
   ],
   "source": [
    "constitution = \"https://www.archives.gov/founding-docs/constitution-transcript\"\n",
    "fd = nltk.FreqDist()\n",
    "freq_words(constitution, fd, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " 'the',\n",
       " \"''\",\n",
       " 'of',\n",
       " 'and',\n",
       " 'shall',\n",
       " '.',\n",
       " 'be',\n",
       " 'to',\n",
       " ';',\n",
       " ':',\n",
       " 'in',\n",
       " 'states',\n",
       " 'or',\n",
       " ':1',\n",
       " 'a',\n",
       " 'united',\n",
       " 'state',\n",
       " 'by',\n",
       " 'for',\n",
       " '{',\n",
       " '}',\n",
       " '(',\n",
       " ')',\n",
       " 'any',\n",
       " 'on',\n",
       " 'all',\n",
       " 'which',\n",
       " 'president',\n",
       " 'may']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def freq_words(url, n):\n",
    "    html = request.urlopen(url).read().decode('utf8')\n",
    "    text = BeautifulSoup(html).get_text()\n",
    "    freqdist = nltk.FreqDist(word.lower() for word in nltk.word_tokenize(text))\n",
    "    return [word for (word, _) in fd.most_common(n)]\n",
    "freq_words(constitution, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(reference, test):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of test items that equal the corresponding reference items.\n",
    "\n",
    "    Given a list of reference values and a corresponding list of test values,\n",
    "    return the fraction of corresponding values that are equal.\n",
    "    In particular, return the fraction of indexes\n",
    "    {0<i<=len(test)} such that C{test[i] == reference[i]}.\n",
    "\n",
    "        >>> accuracy(['ADJ', 'N', 'V', 'N'], ['N', 'N', 'V', 'ADJ'])\n",
    "        0.5\n",
    "\n",
    "    :param reference: An ordered list of reference values\n",
    "    :type reference: list\n",
    "    :param test: A list of values to compare against the corresponding\n",
    "        reference values\n",
    "    :type test: list\n",
    "    :return: the accuracy score\n",
    "    :rtype: float\n",
    "    :raises ValueError: If reference and length do not have the same length\n",
    "    \"\"\"\n",
    "\n",
    "    if len(reference) != len(test):\n",
    "        raise ValueError(\"Lists must have the same length.\")\n",
    "    num_correct = 0\n",
    "    for x, y in zip(reference, test):\n",
    "        if x == y:\n",
    "            num_correct += 1\n",
    "    return float(num_correct) / len(reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
